# ğŸš€ Computational Truth Architecture
## Komission VDG ê³ ë„í™” ë§ˆìŠ¤í„° ë¡œë“œë§µ

**ì‘ì„±**: 2026-01-01  
**ëª©í‘œ**: ì •ì  íŒ¨í„´ ë¶„ì„ â†’ ë™ì  ë² ì´ì§€ì•ˆ ì§„ì‹¤ ì—”ì§„ìœ¼ë¡œ ì§„í™”

---

## Executive Summary

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    COMPUTATIONAL TRUTH ENGINE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Phase 1 â”‚â”€â”€â”€â”€â–¶â”‚  Phase 2 â”‚â”€â”€â”€â”€â–¶â”‚  Phase 3 â”‚â”€â”€â”€â”€â–¶â”‚  Phase 4 â”‚   â”‚
â”‚  â”‚ ì œ1ì›ë¦¬  â”‚     â”‚ ë³€ìˆ˜ë§¤í•‘ â”‚     â”‚ ë² ì´ì§€ì•ˆ â”‚     â”‚  Kelly   â”‚   â”‚
â”‚  â”‚  âœ… 95%  â”‚     â”‚  âš ï¸ 70%  â”‚     â”‚  âš ï¸ 50%  â”‚     â”‚  âŒ 10%  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                â”‚                â”‚                â”‚        â”‚
â”‚         â–¼                â–¼                â–¼                â–¼        â”‚
â”‚   Invariant/       Exponential/      Dynamic           Optimal      â”‚
â”‚   Variable         Logarithmic       Updating          Betting      â”‚
â”‚   Separation       Transforms        Truth             Ratio        â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› Phase 1: ì œ1ì›ë¦¬ (Free Energy & Renormalization)

### í˜„ì¬ ìƒíƒœ: âœ… **95% êµ¬í˜„**

#### 1.1 êµ¬í˜„ ì™„ë£Œ í•­ëª©

| ì´ë¡  | êµ¬í˜„ì²´ | íŒŒì¼ ìœ„ì¹˜ |
|------|--------|-----------|
| **Entropy ìµœì†Œí™”** | `hook_genome.pattern` | `vdg_v4.py:HookGenome` |
| **Scale Invariance** | `invariant_elements[]` | `vdg_v4.py:CapsuleBrief` |
| **Handicap Filter** | `evidence_comment_ranks` | `viral_kicks.evidence_*` |

#### 1.2 í•µì‹¬ ì½”ë“œ ë§¤í•‘

```python
# ì œ1ì›ë¦¬: Invariant (í†µì œ ë³€ì¸) vs Variable (ê°€ë³€ ìš”ì¸) ë¶„ë¦¬
class CapsuleBrief(BaseModel):
    invariant_elements: List[str]   # ğŸ”’ ë°˜ë“œì‹œ ìœ ì§€ (Scale-Invariant)
    variable_elements: List[str]    # ğŸ”€ ìê¸° ìƒ‰ê¹” í—ˆìš©
    do_not: List[str]               # ğŸš« ê¸ˆì§€ í–‰ë™ (Handicap Filter)
    product_slot: Optional[str]     # ğŸ“¦ ì œí’ˆ ì‚½ì… íƒ€ì´ë°
```

#### 1.3 Remaining 5%: ë¯¸ì„¸ ê°œì„ 

| í•­ëª© | í˜„ì¬ | ëª©í‘œ | ìš°ì„ ìˆœìœ„ |
|------|------|------|----------|
| ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê²€ì¦ | ê°œì¸â†’í”Œë«í¼ | ê°œì¸â†’í”Œë«í¼â†’ê¸€ë¡œë²Œ | P2 |
| Entropy ì ìˆ˜í™” | ì •ì„±ì  | $H(X) = -\sum p(x) \log p(x)$ | P1 |

---

## ğŸ§® Phase 2: ë³€ìˆ˜ ì•„í‚¤í…ì²˜ (Non-linear Dynamics)

### í˜„ì¬ ìƒíƒœ: âš ï¸ **70% êµ¬í˜„**

#### 2.1 êµ¬í˜„ ì™„ë£Œ ($E$, $H$, $S$)

```python
# $E$ (Exponential): ë„¤íŠ¸ì›Œí¬ íš¨ê³¼
class ViralKick(BaseModel):
    mechanism: str           # "dopamine_spike", "pattern_break" ë“±
    evidence_comment_ranks: List[int]  # ë°”ì´ëŸ´ ì¦í­ ì¦ê±°

# $H$ (Handicap Filter): Costly Signal ê²€ì¦
class CommentEvidence(Base):
    like_count: int          # ë¹„ìš© ì‹ í˜¸ (ë§ì€ ì¢‹ì•„ìš” = ì‹ ë¢°)
    matched_kick_ids: JSONB  # í‚¥ê³¼ ì—°ê²°ëœ ì¦ê±°

# $S$ (Sigmoid Gatekeeper): ì„ê³„ì  í•„í„°
from quality_gate import proof_grade_gate
proof_ready, issues = proof_grade_gate.validate(vdg, duration_ms)
# proof_ready=False â†’ ì§„ì… ê¸ˆì§€ (0ì  ì²˜ë¦¬)
```

#### 2.2 ë¯¸êµ¬í˜„: $L$ (Logarithmic ì²´ê°)

**ë¬¸ì œ**: í˜„ì¬ ëª¨ë“  ì ìˆ˜ê°€ ì„ í˜• â†’ í•œê³„íš¨ìš© ì²´ê° ë¯¸ë°˜ì˜

**í•´ê²°ì•ˆ**:

```python
# ì œì•ˆ: ë¡œê·¸ ìŠ¤ì¼€ì¼ ë³€í™˜ ìœ í‹¸ë¦¬í‹°
def apply_diminishing_returns(value: float, base: float = 10.0) -> float:
    """ë² ë²„-í˜íˆë„ˆ ë²•ì¹™: í•œê³„íš¨ìš© ì²´ê°"""
    if value <= 0:
        return 0.0
    return math.log(value + 1, base) / math.log(base + 1, base)

# ì ìš© ì˜ˆì‹œ
hook_strength_log = apply_diminishing_returns(raw_strength * 10)
view_count_log = apply_diminishing_returns(view_count / 1000)
```

#### 2.3 Phase 2 ë¡œë“œë§µ

| ë‹¨ê³„ | ì‘ì—… | ì†Œìš” | ìš°ì„ ìˆœìœ„ |
|------|------|------|----------|
| 2.3.1 | `LogarithmicTransform` ìœ í‹¸ ì¶”ê°€ | 2h | P1 |
| 2.3.2 | `hook_genome.strength`ì— ë¡œê·¸ ì ìš© | 1h | P1 |
| 2.3.3 | `viral_kicks.confidence`ì— ë¡œê·¸ ì ìš© | 1h | P1 |
| 2.3.4 | ë¹„ì„ í˜• ë³€í™˜ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìƒì„± | 4h | P2 |

---

## ğŸ“Š Phase 3: ë² ì´ì§€ì•ˆ ë™ì  ê°±ì‹  (Bayesian Updating)

### í˜„ì¬ ìƒíƒœ: âš ï¸ **50% êµ¬í˜„**

#### 3.1 êµ¬í˜„ ì™„ë£Œ: PatternCalibrator

```python
# ì´ë¯¸ êµ¬í˜„ë¨! âœ… services/pattern_calibrator.py
class PatternCalibrator:
    """
    ì‹¤ì œ ì„±ê³¼ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒ¨í„´ ì‹ ë¢°ë„ë¥¼ ë³´ì •í•˜ëŠ” ì„œë¹„ìŠ¤
    
    ì‘ë™ ë°©ì‹:
    1. ì˜ìƒ ë¶„ì„ ì‹œ predicted_retention ê¸°ë¡
    2. ì‹¤ì œ ì—…ë¡œë“œ í›„ actual_retention ìˆ˜ì§‘
    3. ì˜¤ì°¨(error) ê³„ì‚° â†’ pattern_confidence ì—…ë°ì´íŠ¸
    4. ë‹¤ìŒ ì˜ˆì¸¡ ì‹œ confidence ê°€ì¤‘ì¹˜ ì ìš©
    """
    
    async def _update_pattern_confidence(self, ...):
        # ì´ë™ í‰ê· ìœ¼ë¡œ ì‹ ë¢°ë„ ê°±ì‹ 
        new_confidence = max(0.0, min(1.0, 1.0 - new_avg_error))
```

#### 3.2 êµ¬í˜„ ì™„ë£Œ: CoachingOutcome (RL í”¼ë“œë°±)

```python
# ì´ë¯¸ êµ¬í˜„ë¨! âœ… models.py + coaching_repository.py
class CoachingOutcome(Base):
    session_id: UUID              # ì½”ì¹­ ì„¸ì…˜
    rule_id: str                  # ì ìš©ëœ ê·œì¹™
    t_sec: float                  # íƒ€ì´ë°
    compliance: bool              # ì‚¬ìš©ì ì¤€ìˆ˜ ì—¬ë¶€
    metric_before: Optional[str]  # ì´ì „ ë©”íŠ¸ë¦­
    metric_after: Optional[str]   # ì´í›„ ë©”íŠ¸ë¦­
    feedback_type: str            # positive/negative/neutral
```

#### 3.3 êµ¬í˜„ ì™„ë£Œ: Parent-Kids ê³„ì¸µ êµ¬ì¡°

```python
# ì´ë¯¸ êµ¬í˜„ë¨! âœ… models.py
class RemixNode(Base):
    parent_node_id: Optional[UUID]  # ë¶€ëª¨ ë…¸ë“œ (Original)
    genealogy_depth: int            # ì„¸ëŒ€ ê¹Šì´ (0=Parent, 1=Kid, 2=Grandkid)
    
    # ê´€ê³„ ë§¤í•‘
    parent: relationship("RemixNode", back_populates="children")
    children: relationship("RemixNode", back_populates="parent")
```

#### 3.4 ë¯¸êµ¬í˜„: ì§„ì •í•œ ë² ì´ì§€ì•ˆ ê³µì‹

**í˜„ì¬ í•œê³„**: ì´ë™ í‰ê·  = **ê·¼ì‚¬ ë² ì´ì§€ì•ˆ** (ì •í™•í•œ ìˆ˜ì‹ ì•„ë‹˜)

**ëª©í‘œ ê³µì‹**:
$$P(Truth|Evidence) = \frac{P(Evidence|Truth) \times P(Truth)}{P(Evidence)}$$

**êµ¬í˜„ ë¡œë“œë§µ**:

```python
# ì œì•ˆ: ì •ë°€ ë² ì´ì§€ì•ˆ ê°±ì‹ ê¸°
class BayesianPatternUpdater:
    """
    ë² ì´ì§€ì•ˆ ì •ë¦¬ ê¸°ë°˜ íŒ¨í„´ ì‹ ë¢°ë„ ê°±ì‹ 
    """
    
    def update_posterior(
        self,
        prior: float,              # P(Truth) - ê¸°ì¡´ ì‹ ë¢°ë„
        likelihood: float,         # P(Evidence|Truth) - ì„±ê³µ ì‹œ ê´€ì°° í™•ë¥ 
        evidence_prob: float,      # P(Evidence) - ì „ì²´ ê´€ì°° í™•ë¥ 
    ) -> float:
        """ì •ë°€ ë² ì´ì§€ì•ˆ ê°±ì‹ """
        posterior = (likelihood * prior) / evidence_prob
        return min(1.0, max(0.0, posterior))
    
    def batch_update(
        self,
        prior: float,
        outcomes: List[CoachingOutcome],
    ) -> float:
        """ë‹¤ì¤‘ ì¦ê±° ì¼ê´„ ê°±ì‹ """
        current = prior
        for outcome in outcomes:
            # ì„±ê³µ ì‹œ likelihood ë†’ìŒ, ì‹¤íŒ¨ ì‹œ ë‚®ìŒ
            likelihood = 0.9 if outcome.compliance else 0.2
            # Evidence probabilityëŠ” ì „ì²´ ì„±ê³µë¥ ì—ì„œ ì¶”ì •
            evidence_prob = self._estimate_evidence_prob(outcome.rule_id)
            current = self.update_posterior(current, likelihood, evidence_prob)
        return current
    
    def _estimate_evidence_prob(self, rule_id: str) -> float:
        """ì „ì²´ ë°ì´í„°ì—ì„œ ì¦ê±° ë°œìƒ í™•ë¥  ì¶”ì •"""
        # DBì—ì„œ í•´ë‹¹ rule_idì˜ ì „ì²´ ì„±ê³µë¥  ì¡°íšŒ
        total_trials = self.get_total_trials(rule_id)
        successful_trials = self.get_successful_trials(rule_id)
        return (successful_trials + 1) / (total_trials + 2)  # Laplace smoothing
```

#### 3.5 ë¯¸êµ¬í˜„: Entropy Multiplier

**ëª©í‘œ**: ì˜ˆìƒ vs ì‹¤ì œ ì°¨ì´(Gap)ì˜ ì •ë³´ëŸ‰ì„ ìŠ¹ìˆ˜ë¡œ ì ìš©

```python
# ì œì•ˆ: Shannon Entropy ê¸°ë°˜ ê°€ì¤‘ì¹˜
def calculate_entropy_multiplier(
    predicted: float,
    actual: float,
) -> float:
    """
    ì˜ˆìƒê³¼ ì‹¤ì œì˜ ì°¨ì´ê°€ í´ìˆ˜ë¡ ì •ë³´ ê°€ì¹˜ ë†’ìŒ
    
    ì„€ë„Œ ì—”íŠ¸ë¡œí”¼: H(X) = -Î£ p(x) log p(x)
    """
    gap = abs(actual - predicted)
    
    # Gapì´ 0ì´ë©´ ì •ë³´ëŸ‰ 0 (ë»”í•œ ê²°ê³¼)
    if gap < 0.01:
        return 1.0  # ê¸°ë³¸ ìŠ¹ìˆ˜
    
    # Gapì´ í´ìˆ˜ë¡ ë†’ì€ ìŠ¹ìˆ˜ (ìµœëŒ€ 2.0)
    # ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ í­ë°œ ë°©ì§€
    entropy = -gap * math.log2(gap + 0.01)
    multiplier = 1.0 + min(1.0, entropy)
    
    return multiplier
```

#### 3.6 Phase 3 ë¡œë“œë§µ

| ë‹¨ê³„ | ì‘ì—… | ì†Œìš” | ìš°ì„ ìˆœìœ„ | ì˜ì¡´ì„± |
|------|------|------|----------|--------|
| 3.6.1 | `BayesianPatternUpdater` í´ë˜ìŠ¤ ìƒì„± | 4h | P0 | - |
| 3.6.2 | `PatternCalibrator`ë¥¼ ë² ì´ì§€ì•ˆìœ¼ë¡œ êµì²´ | 3h | P0 | 3.6.1 |
| 3.6.3 | `calculate_entropy_multiplier()` ìœ í‹¸ | 2h | P1 | - |
| 3.6.4 | `viral_kicks.confidence`ì— ì ìš© | 2h | P1 | 3.6.2, 3.6.3 |
| 3.6.5 | ì‹¤ì‹œê°„ ì½”ì¹­ ì‹œ ë² ì´ì§€ì•ˆ ê°±ì‹  ì—°ë™ | 4h | P1 | 3.6.2 |
| 3.6.6 | NotebookLM Distill ê²°ê³¼ ë² ì´ì§€ì•ˆ ì£¼ì… | 3h | P2 | 3.6.2 |

---

## âš–ï¸ Phase 4: Kelly Criterion (ìµœì  ìì› ë°°ë¶„)

### í˜„ì¬ ìƒíƒœ: âŒ **10% êµ¬í˜„**

#### 4.1 ì´ë¡ ì  ë°°ê²½

$$f^* = \frac{bp - q}{b}$$

| ë³€ìˆ˜ | ì˜ë¯¸ | VDG ë§¤í•‘ |
|------|------|----------|
| $f^*$ | ìµœì  ìì› íˆ¬ì… ë¹„ìœ¨ | `recommended_effort_percent` |
| $b$ | ì„±ê³µ ì‹œ ê¸°ëŒ€ ìˆ˜ìµ | `expected_viral_multiplier` |
| $p$ | ì„±ê³µ í™•ë¥  | `replication_success_rate` |
| $q$ | ì‹¤íŒ¨ í™•ë¥  ($1-p$) | - |

#### 4.2 í˜„ì¬ êµ¬í˜„ (10%)

```python
# ë¶€ë¶„ êµ¬í˜„: CoachingSessionì— compliance_target ì¡´ì¬
class CoachingSession(Base):
    target_pattern_id: str
    target_compliance_rate: float  # ëª©í‘œ ì¤€ìˆ˜ìœ¨ (pì˜ ê·¼ì‚¬)
```

#### 4.3 ì™„ì „ êµ¬í˜„ ì„¤ê³„

```python
# ì œì•ˆ: Kelly Criterion ê³„ì‚°ê¸°
class KellyCriterionCalculator:
    """
    ìµœì  ìì› ë°°ë¶„ ë¹„ìœ¨ ê³„ì‚°ê¸°
    
    ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤:
    - í¬ë¦¬ì—ì´í„°: "ì´ íŒ¨í„´ ë”°ë¼í•  ë•Œ ì–¼ë§ˆë‚˜ ì‹œê°„ íˆ¬ìí•´ì•¼ í•´?"
    - ë¸Œëœë“œ: "ì´ O2O ìº í˜ì¸ì— ì˜ˆì‚° ëª‡ % ë°°íŒ…í•´ì•¼ í•´?"
    """
    
    def calculate_optimal_bet(
        self,
        success_probability: float,    # p: AI ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
        expected_multiplier: float,    # b: ê³¼ê±° ë°ì´í„° ê¸°ë°˜ ê¸°ëŒ€ ìˆ˜ìµ
        current_confidence: float,     # ë² ì´ì§€ì•ˆ ì‹ ë¢°ë„
    ) -> Dict[str, Any]:
        """ì¼ˆë¦¬ ê³µì‹ ì ìš©"""
        
        # ê¸°ë³¸ ì¼ˆë¦¬ ê³„ì‚°
        p = success_probability
        q = 1 - p
        b = expected_multiplier
        
        kelly_fraction = (b * p - q) / b
        
        # ì‹ ë¢°ë„ ë³´ì • (í™•ì‹  ë‚®ìœ¼ë©´ ë² íŒ… ì¤„ì„)
        adjusted_fraction = kelly_fraction * current_confidence
        
        # ìµœì¢… ê¶Œê³ 
        if adjusted_fraction < 0:
            signal = "NO_GO"
            reason = "ê¸°ëŒ€ê°’ ìŒìˆ˜: ì§„ì… ê¸ˆì§€"
        elif adjusted_fraction < 0.1:
            signal = "CAUTION"
            reason = "ë‚®ì€ ê¸°ëŒ€ê°’: ìµœì†Œ íˆ¬ìë§Œ"
        elif adjusted_fraction < 0.3:
            signal = "MODERATE"
            reason = "ì ì • ê¸°ëŒ€ê°’: ì¤‘ê°„ íˆ¬ì"
        else:
            signal = "GO"
            reason = "ë†’ì€ ê¸°ëŒ€ê°’: ì ê·¹ íˆ¬ì"
        
        return {
            "kelly_fraction": round(max(0, kelly_fraction), 4),
            "adjusted_fraction": round(max(0, adjusted_fraction), 4),
            "recommended_effort_percent": round(max(0, adjusted_fraction) * 100, 1),
            "signal": signal,
            "reason": reason,
            "inputs": {
                "success_probability": p,
                "expected_multiplier": b,
                "confidence": current_confidence,
            }
        }
    
    def simulate_scenarios(
        self,
        pattern_id: str,
        db: AsyncSession,
    ) -> Dict[str, Any]:
        """Tree of Thoughts: 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜"""
        
        # ê³¼ê±° ë°ì´í„°ì—ì„œ í†µê³„ ì¶”ì¶œ
        stats = await self._get_pattern_stats(pattern_id, db)
        
        return {
            "best_case": self.calculate_optimal_bet(
                success_probability=stats["p_90th"],
                expected_multiplier=stats["multiplier_90th"],
                current_confidence=stats["confidence"],
            ),
            "normal_case": self.calculate_optimal_bet(
                success_probability=stats["p_median"],
                expected_multiplier=stats["multiplier_median"],
                current_confidence=stats["confidence"],
            ),
            "worst_case": self.calculate_optimal_bet(
                success_probability=stats["p_10th"],
                expected_multiplier=stats["multiplier_10th"],
                current_confidence=stats["confidence"],
            ),
        }
```

#### 4.4 VDG ìŠ¤í‚¤ë§ˆ í™•ì¥

```python
# ì œì•ˆ: VDGv4.1ì— ì¶”ê°€
class ReplicationGuidance(BaseModel):
    """ì‚¬ìš©ìë¥¼ ìœ„í•œ ë³µì œ ê°€ì´ë“œ"""
    
    # ë² ì´ì§€ì•ˆ ì‹ ë¢°ë„
    pattern_confidence: float = Field(ge=0.0, le=1.0)
    confidence_sample_count: int
    
    # ì¼ˆë¦¬ ê¸°ì¤€ ê²°ê³¼
    success_probability: float = Field(ge=0.0, le=1.0)
    expected_viral_multiplier: float = Field(ge=0.0)
    kelly_fraction: float
    recommended_effort_percent: float = Field(ge=0.0, le=100.0)
    
    # ìµœì¢… ì‹ í˜¸
    go_nogo_signal: Literal["GO", "MODERATE", "CAUTION", "NO_GO"]
    signal_reason: str
    
    # ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜
    best_case_effort: float
    normal_case_effort: float
    worst_case_effort: float

class VDGv41(VDGv4):
    """VDG v4.1: Kelly Criterion í™•ì¥"""
    vdg_version: str = "4.1.0"
    replication_guidance: Optional[ReplicationGuidance] = None
```

#### 4.5 Phase 4 ë¡œë“œë§µ

| ë‹¨ê³„ | ì‘ì—… | ì†Œìš” | ìš°ì„ ìˆœìœ„ | ì˜ì¡´ì„± |
|------|------|------|----------|--------|
| 4.5.1 | `KellyCriterionCalculator` í´ë˜ìŠ¤ | 6h | P0 | Phase 3 ì™„ë£Œ |
| 4.5.2 | `ReplicationGuidance` ìŠ¤í‚¤ë§ˆ | 2h | P0 | - |
| 4.5.3 | VDG v4.1 ë§ˆì´ê·¸ë ˆì´ì…˜ | 3h | P0 | 4.5.2 |
| 4.5.4 | `simulate_scenarios()` ToT êµ¬í˜„ | 4h | P1 | 4.5.1 |
| 4.5.5 | í”„ë¡ íŠ¸ì—”ë“œ Go/No-Go í‘œì‹œ | 4h | P1 | 4.5.3 |
| 4.5.6 | ì½”ì¹­ ì„¸ì…˜ ì‹œì‘ ì „ Kelly ê²€ì¦ | 3h | P1 | 4.5.1 |

---

## ğŸ”„ Phase 5: NotebookLM ë‹¤ì¤‘ ê¹Šì´ ë…¸ë“œí™” (Future)

### ëª©í‘œ: Parent-Kids ê³„ì¸µì„ ë¬´í•œ ê¹Šì´ë¡œ í™•ì¥

#### 5.1 í˜„ì¬ êµ¬í˜„

```
Parent (Depth 0)
â””â”€â”€ Kid 1 (Depth 1)
â””â”€â”€ Kid 2 (Depth 1)
â””â”€â”€ Kid 3 (Depth 1)
```

#### 5.2 ëª©í‘œ êµ¬ì¡°

```
Parent (Depth 0)
â”œâ”€â”€ Kid 1.1 (Depth 1)
â”‚   â”œâ”€â”€ Grandkid 1.1.1 (Depth 2)
â”‚   â””â”€â”€ Grandkid 1.1.2 (Depth 2)
â”‚       â””â”€â”€ GreatGrandkid (Depth 3)
â”œâ”€â”€ Kid 1.2 (Depth 1)
â””â”€â”€ Kid 1.3 (Depth 1)
```

#### 5.3 ì„¤ê³„ ì›ì¹™

```python
# ì œì•ˆ: ê³„ì¸µì  íŒ¨í„´ ì§„í™” ì¶”ì 
class PatternLineage(BaseModel):
    """íŒ¨í„´ ê³„ë³´ ì¶”ì """
    
    # í˜„ì¬ ë…¸ë“œ
    node_id: UUID
    depth: int
    
    # ì¡°ìƒ ì²´ì¸
    ancestor_chain: List[UUID]  # [parent, grandparent, great-grandparent, ...]
    
    # ì§„í™” ë©”íƒ€ë°ì´í„°
    mutation_from_parent: Dict[str, Any]  # ë¶€ëª¨ ëŒ€ë¹„ ë³€í™”
    invariant_preserved: List[str]        # ìœ ì§€ëœ ë¶ˆë³€ìš”ì†Œ
    variable_mutated: List[str]           # ë³€ê²½ëœ ê°€ë³€ìš”ì†Œ
    
    # ì„±ê³¼ ë¹„êµ
    performance_delta: float              # ë¶€ëª¨ ëŒ€ë¹„ ì„±ëŠ¥ ë³€í™”
    survival_probability: float           # ë‹¤ìŒ ì„¸ëŒ€ ìƒì¡´ í™•ë¥  (ë² ì´ì§€ì•ˆ)

class DepthDistiller:
    """ë‹¤ì¤‘ ê¹Šì´ì—ì„œ íŒ¨í„´ ì •ì œ"""
    
    async def distill_at_depth(
        self,
        cluster_id: str,
        max_depth: int,
        min_samples_per_depth: int = 3,
    ) -> Dict[str, Any]:
        """íŠ¹ì • ê¹Šì´ì—ì„œ ê³µí†µ íŒ¨í„´ ì¶”ì¶œ"""
        
        nodes = await self._get_nodes_at_depth(cluster_id, max_depth)
        
        # ê° ê¹Šì´ë³„ ë¶ˆë³€ìš”ì†Œ êµì§‘í•©
        invariants_by_depth = {}
        for depth in range(max_depth + 1):
            depth_nodes = [n for n in nodes if n.depth == depth]
            if len(depth_nodes) >= min_samples_per_depth:
                invariants_by_depth[depth] = self._find_common_invariants(depth_nodes)
        
        # ê¹Šì´ ê°„ ë¶ˆë³€ìš”ì†Œ ë³€í™” ì¶”ì 
        invariant_decay = self._calculate_invariant_decay(invariants_by_depth)
        
        return {
            "invariants_by_depth": invariants_by_depth,
            "invariant_decay": invariant_decay,
            "strongest_invariants": self._find_strongest(invariant_decay),
            "recommended_max_depth": self._optimal_depth(invariant_decay),
        }
```

#### 5.4 Phase 5 ë¡œë“œë§µ

| ë‹¨ê³„ | ì‘ì—… | ì†Œìš” | ìš°ì„ ìˆœìœ„ | ì˜ì¡´ì„± |
|------|------|------|----------|--------|
| 5.4.1 | `PatternLineage` ìŠ¤í‚¤ë§ˆ | 4h | P2 | Phase 4 |
| 5.4.2 | `DepthDistiller` ì„œë¹„ìŠ¤ | 8h | P2 | 5.4.1 |
| 5.4.3 | NotebookLM API ì—°ë™ | 6h | P2 | 5.4.2 |
| 5.4.4 | ìë™ ê¹Šì´ í™•ì¥ íŠ¸ë¦¬ê±° | 4h | P3 | 5.4.3 |
| 5.4.5 | ê³„ë³´ ì‹œê°í™” UI | 6h | P3 | 5.4.4 |

---

## ğŸ“… í†µí•© ë§ˆìŠ¤í„° íƒ€ì„ë¼ì¸

```mermaid
gantt
    title Computational Truth Architecture êµ¬í˜„ ë¡œë“œë§µ
    dateFormat  YYYY-MM-DD
    
    section Phase 2: ë¹„ì„ í˜•
    Logarithmic Transform  :p2a, 2026-01-02, 4h
    Hook Strength ì ìš©     :p2b, after p2a, 2h
    
    section Phase 3: ë² ì´ì§€ì•ˆ
    BayesianPatternUpdater :p3a, 2026-01-03, 4h
    PatternCalibrator êµì²´ :p3b, after p3a, 3h
    Entropy Multiplier     :p3c, after p3b, 2h
    ì‹¤ì‹œê°„ ì½”ì¹­ ì—°ë™       :p3d, after p3c, 4h
    
    section Phase 4: Kelly
    KellyCriterionCalculator:p4a, 2026-01-05, 6h
    ReplicationGuidance    :p4b, after p4a, 2h
    VDG v4.1 ë§ˆì´ê·¸ë ˆì´ì…˜  :p4c, after p4b, 3h
    ToT ì‹œë®¬ë ˆì´ì…˜         :p4d, after p4c, 4h
    
    section Phase 5: ë‹¤ì¤‘ê¹Šì´
    PatternLineage ìŠ¤í‚¤ë§ˆ  :p5a, 2026-01-10, 4h
    DepthDistiller         :p5b, after p5a, 8h
```

---

## ğŸ¯ Critical Derivative (ìµœì†Œ ë…¸ë ¥, ìµœëŒ€ íš¨ê³¼)

> **Phase 3.6.2**: `PatternCalibrator`ë¥¼ ì •ë°€ ë² ì´ì§€ì•ˆìœ¼ë¡œ êµì²´

**ì´ìœ **:
1. ì´ë¯¸ êµ¬ì¡°ê°€ ì¡´ì¬ (ë¦¬íŒ©í† ë§ë§Œ í•„ìš”)
2. Phase 4 (Kelly)ì˜ í•„ìˆ˜ ì „ì œì¡°ê±´
3. ëª¨ë“  ì‹ ë¢°ë„ ê³„ì‚°ì˜ SSoT (Single Source of Truth)

---

## ğŸ“Š ì™„ë£Œ ì‹œ ì˜ˆìƒ ì •í•©ì„±

| Phase | í˜„ì¬ | ëª©í‘œ | ë‹¬ì„± ì‹œ íš¨ê³¼ |
|-------|------|------|--------------|
| 1 | 95% | 100% | ì œ1ì›ë¦¬ ì™„ì „ ì •ë¦½ |
| 2 | 70% | 95% | ë¹„ì„ í˜• í˜„ì‹¤ ë°˜ì˜ |
| 3 | 50% | 95% | ë™ì  ì§„ì‹¤ ê°±ì‹  |
| 4 | 10% | 90% | ìµœì  ì˜ì‚¬ê²°ì • |
| 5 | 0% | 70% | ë¬´í•œ ê¹Šì´ ì§„í™” |

**Total**: 56% â†’ **90%** (ëª©í‘œ)

---

## í•œ ì¤„ ìš”ì•½

> **"ë°ì´í„°ê°€ ìŒ“ì¼ìˆ˜ë¡ ìŠ¤ìŠ¤ë¡œ ì •êµí•´ì§€ëŠ” ë² ì´ì§€ì•ˆ ì§„ì‹¤ ì—”ì§„ì„ í†µí•´, 
> ì‚¬ìš©ìëŠ” `invariant`ë§Œ ì§€í‚¤ê³  `variable`ì— ìê¸° ìƒ‰ê¹”ì„ ì…íˆë©´ 
> ë™ì¼í•œ ë°”ì´ëŸ´ì„ ì¬í˜„í•  ìˆ˜ ìˆë‹¤."**
