# K-MEME FACTORY v5.2 - Production-Ready (ì‹œë‹ˆì–´ ê°œë°œì í”¼ë“œë°± ì ìš©)
## ìµœì¢… ë‹¨ì¼ì§„ì‹¤ë¬¸ì„œ (Complete, Zero-Gap, Production-Safe ì•„í‚¤í…ì²˜)

---

## ğŸ“‹ Document Overview
**Status**: Production-Ready, Zero-Gap, Security-Hardened
**Version**: 5.2 Final (Senior Developer Review Completed)
**Updated**: 2025-12-22 10:30 KST
**Target Audience**: CTO, ê°œë°œíŒ€, ë³´ì•ˆíŒ€ (ì¦‰ì‹œ ì°©ìˆ˜ ê°€ëŠ¥)
**Key Change**: AI ëª¨ë¸ ë²„ì „ ìˆ˜ì • + ë³´ì•ˆ ì•„í‚¤í…ì²˜ ì¶”ê°€ + ì—ëŸ¬ í•¸ë“¤ë§ ì „ëµ ì¶”ê°€

---

## ğŸ”´ CRITICAL: ì‹œë‹ˆì–´ ê°œë°œì í”¼ë“œë°± ì ìš©ì‚¬í•­

### 1. AI ëª¨ë¸ ë²„ì „ ìˆ˜ì • (ì¦‰ì‹œ ë°˜ì˜)

#### Before (ë¯¸ë˜ ëª¨ë¸)
```
âŒ Gemini 3.0 Pro (ì•„ì§ ë¯¸ì¶œì‹œ)
âŒ Claude 4.5 Opus (ì•„ì§ ë¯¸ì¶œì‹œ)
â†’ ìœ„í—˜: ê°œë°œ ì‹œì ì— ëª¨ë¸ ì—†ìŒ
```

#### After (í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥ ë²„ì „) âœ…
```
âœ… Google Gemini 2.0 Flash Pro (í˜„ì¬ ìµœì‹ , 2025)
   - ì„±ëŠ¥: ì´ì „ Gemini Proì™€ ë™ì¼ ìˆ˜ì¤€
   - ë¹„ìš©: ë” ì €ë ´ ($0.075/1M tokens vs $0.1)
   - ì†ë„: FlashëŠ” 50% ë” ë¹ ë¦„
   - ì‚¬ìš© ê°€ëŠ¥: ì¦‰ì‹œ

âœ… Anthropic Claude 3.5 Sonnet (í˜„ì¬ ìµœì‹ , 2025)
   - ì„±ëŠ¥: ì´ì „ Claude 3 Opus ëŒ€ë¹„ ì„±ëŠ¥ ìš°ìœ„
   - ë¹„ìš©: $3/1M input vs Claude Opus $15
   - ì†ë„: ë” ë¹ ë¦„
   - ì‚¬ìš© ê°€ëŠ¥: ì¦‰ì‹œ

ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½ë¡œ:
- Phase 1 (MVP): Gemini 2.0 + Claude 3.5 ì‚¬ìš©
- 2026+: Gemini 3.0/Claude 4.5 ì¶œì‹œ ì‹œ êµì²´ (API ë˜í¼ë¡œ ìµœì†Œí™”)
```

---

### 2. ë°ì´í„°ë² ì´ìŠ¤ ë‹¨ìˆœí™” (MVP vs Scale)

#### Problem: 5ê°œ DBëŠ” ê³¼ë„í•¨
```
Current: PostgreSQL + PostGIS + Neo4j + Pinecone + Redis
â†’ ìš´ì˜ ë³µì¡ë„: ë†’ìŒ (DevOps ë¶€ë‹´)
â†’ ì´ˆê¸° ìš´ì˜ ë¹„ìš©: ë†’ìŒ
â†’ íŒ€ ì˜¨ë³´ë”©: ì–´ë ¤ì›€
```

#### Solution: Staged Adoption âœ…
```
Phase 1 (MVP, Week 1-12): 3ê°œ DBë§Œ ì‚¬ìš©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… PostgreSQL 16 LTS
   - ê¸°ë³¸ ë…¸ë“œ ë°ì´í„° ì €ì¥
   - ì‚¬ìš©ì, ìº í˜ì¸, ê¶Œí•œ ê´€ë¦¬

âœ… PostGIS (PostgreSQL í™•ì¥)
   - ìœ„ì¹˜ ê¸°ë°˜ O2O ìº í˜ì¸
   - ì§€ë¦¬ ì¿¼ë¦¬ ìµœì í™”

âœ… Redis 7.2
   - Gemini ë¶„ì„ ê²°ê³¼ ìºì‹±
   - ì¸ê¸° ë…¸ë“œ ë Œë”ë§ ìºì‹±
   - Rate Limiting (ì‚¬ìš©ìë‹¹ ìµœëŒ€ ìš”ì²­)
   - Session ê´€ë¦¬

ë²¡í„° ê²€ìƒ‰: pgvector (PostgreSQL í™•ì¥ìœ¼ë¡œ ì¶©ë¶„)
â†’ Pinecone ë¹„ìš© ì œê±° ($300/month ì ˆê°)

ë¹„ìš©: ~$500/month

Phase 2 (Scale, Month 4-6): 5ê°œ DB ë„ì…
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… ê¸°ì¡´ 3ê°œ (PostgreSQL, PostGIS, Redis) ìœ ì§€

â• Neo4j 5.13
   - ì–¸ì œ: ë…¸ë“œ 1,000ê°œ+ ë„ë‹¬ ì‹œì 
   - ìš©ë„: Viral Genealogy Graph ì¿¼ë¦¬ (Parentâ†’Mutationâ†’Child)
   - ì„±ëŠ¥: SQL ëŒ€ë¹„ 10ë°° ë¹ ë¦„ (ê·¸ë˜í”„ ì¿¼ë¦¬)
   - ë¹„ìš©: ~$200/month (Aura í´ë¼ìš°ë“œ)

â• Supabase pgvector ê³ ë„í™”
   - ë²¡í„° ê²€ìƒ‰ ì •êµí™”
   - ìœ ì‚¬ ë°ˆ ì¶”ì²œ ì—”ì§„

ë¹„ìš©: ~$800/month (ì¶”ê°€ $300)

Migration Strategy:
- PostgreSQLì˜ parent_node_id, mutation_profileì„ ë¨¼ì € ì €ì¥
- ë°ì´í„° 1,000ê°œ ë„ë‹¬ ì‹œ Neo4jë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
- ë™ì‹œ ì¡°íšŒ í›„ ì ì§„ì  ì „í™˜
```

---

### 3. ë³´ì•ˆ ì•„í‚¤í…ì²˜ ì¶”ê°€ (Critical)

#### Authentication & Authorization

```python
# FastAPI + OAuth2 + JWT (ê¶Œì¥ íŒ¨í„´)

from fastapi import Depends, HTTPException
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from passlib.context import CryptContext
import firebase_admin
from firebase_admin import credentials, auth

class SecurityConfig:
    """
    ì¸ì¦/ì¸ê°€ ì„¤ì •
    """
    
    # 1. Firebase Authentication (ì¶”ì²œ: Google/Apple/Email ì†Œì…œ ë¡œê·¸ì¸)
    # ëŒ€ì²´: Auth0, Supabase Auth
    firebase_config = {
        "type": "service_account",
        "project_id": "k-meme-factory",
        "private_key_id": "...",
        "private_key": "...",
        "client_email": "...",
        "client_id": "...",
        "auth_uri": "https://accounts.google.com/o/oauth2/auth",
        "token_uri": "https://oauth2.googleapis.com/token",
        "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs"
    }
    
    # 2. JWT (API í† í°)
    SECRET_KEY = "your-secret-key-from-env"  # .envì—ì„œ ë¡œë“œ
    ALGORITHM = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES = 30
    REFRESH_TOKEN_EXPIRE_DAYS = 7


async def get_current_user(token: str = Depends(OAuth2PasswordBearer(tokenUrl="token"))) -> dict:
    """
    JWT í† í°ì—ì„œ í˜„ì¬ ì‚¬ìš©ì ì¶”ì¶œ
    """
    try:
        decoded_token = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = decoded_token.get("sub")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Invalid authentication")
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")
    
    user = await db.get_user(user_id)
    if user is None:
        raise HTTPException(status_code=404, detail="User not found")
    
    return user


async def require_admin(current_user: dict = Depends(get_current_user)) -> dict:
    """
    Admin ê¶Œí•œ í™•ì¸
    """
    if current_user.get('role') != 'admin':
        raise HTTPException(status_code=403, detail="Admin access required")
    return current_user


@app.post("/token")
async def login(form_data: OAuth2PasswordRequestForm = Depends()):
    """
    OAuth2 ë¡œê·¸ì¸ (Firebase ì—°ë™)
    """
    try:
        # Firebaseì—ì„œ í† í° ê²€ì¦
        decoded_token = auth.verify_id_token(form_data.password)  # form_data.password = Firebase ID Token
        user_id = decoded_token['uid']
        
        # JWT í† í° ìƒì„±
        access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
        expire = datetime.utcnow() + access_token_expires
        to_encode = {"sub": user_id, "exp": expire}
        encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
        
        return {"access_token": encoded_jwt, "token_type": "bearer"}
    
    except Exception as e:
        raise HTTPException(status_code=401, detail="Invalid credentials")
```

#### API Rate Limiting & Throttling

```python
from slowapi import Limiter
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)

@app.post("/api/remix/analyze")
@limiter.limit("10/minute")  # ë¶„ë‹¹ 10íšŒ ì œí•œ
async def analyze_video(video_url: str, current_user: dict = Depends(get_current_user)):
    """
    Gemini ë¶„ì„ API
    Rate Limit: ë¶„ë‹¹ 10íšŒ, ì‹œê°„ë‹¹ 100íšŒ
    """
    
    # ì‚¬ìš©ìë³„ ì¼ì¼ í• ë‹¹ëŸ‰ í™•ì¸
    daily_quota = await redis.get(f"quota:{current_user['id']}:daily")
    if daily_quota and int(daily_quota) >= 50:  # ì¼ì¼ 50íšŒ ì œí•œ
        raise HTTPException(status_code=429, detail="Daily quota exceeded")
    
    # Gemini í˜¸ì¶œ (ìºì‹± ì ìš©)
    cache_key = f"gemini:{video_url}"
    cached_result = await redis.get(cache_key)
    
    if cached_result:
        return json.loads(cached_result)
    
    # API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ ì ìš©)
    analysis = await call_with_retry(
        lambda: gemini.analyze_video(video_url),
        max_retries=3,
        backoff=2
    )
    
    # ê²°ê³¼ ìºì‹± (24ì‹œê°„)
    await redis.setex(cache_key, 86400, json.dumps(analysis))
    
    # í• ë‹¹ëŸ‰ ì¦ê°€
    await redis.incr(f"quota:{current_user['id']}:daily")
    
    return analysis
```

#### SQL Injection & XSS ë°©ì§€

```python
# âœ… Good: Parameterized Queries (ìë™ìœ¼ë¡œ injection ë°©ì§€)
from sqlalchemy.orm import Session

def get_remix_node(db: Session, node_id: str):
    # ORM ì‚¬ìš© (ì¿¼ë¦¬ ìë™ íŒŒë¼ë¯¸í„°í™”)
    return db.query(RemixNode).filter(RemixNode.node_id == node_id).first()

# âŒ Bad: String Interpolation (ìœ„í—˜)
# query = f"SELECT * FROM remix_nodes WHERE node_id = '{node_id}'"

# âœ… Good: HTML Escaping
from markupsafe import escape

def render_user_content(content: str) -> str:
    """
    ì‚¬ìš©ì ì…ë ¥ ì½˜í…ì¸  ì•ˆì „ ë Œë”ë§
    """
    return escape(content)  # <, >, &, ", ' ëª¨ë‘ ì´ìŠ¤ì¼€ì´í”„

# âœ… Good: DOMPurify (í”„ë¡ íŠ¸ì—”ë“œ)
// React ì»´í¬ë„ŒíŠ¸ì—ì„œ
import DOMPurify from 'dompurify';

<div dangerouslySetInnerHTML={{__html: DOMPurify.sanitize(userContent)}} />
```

#### ë°ì´í„° ë³´í˜¸ (GDPR)

```python
class UserDataProtection:
    """
    ê°œì¸ì •ë³´ ë³´í˜¸ ë° GDPR ì¤€ìˆ˜
    """
    
    async def anonymize_user_data(self, user_id: str):
        """
        ì‚¬ìš©ì ìš”ì²­ ì‹œ ë°ì´í„° ìµëª…í™” (Right to be forgotten)
        """
        user = await db.get_user(user_id)
        
        # 1. ê°œì¸ ì‹ë³„ ì •ë³´ ì œê±°
        user.update({
            'email': f'anonymized_{uuid.uuid4()}@deleted.local',
            'name': 'Deleted User',
            'phone': None,
            'address': None
        })
        
        # 2. í™œë™ ê¸°ë¡ ì œê±° (ë‹¨, ê°ì‚¬ ë¡œê·¸ëŠ” ìœ ì§€)
        await db.delete_user_videos(user_id)
        await db.delete_user_interactions(user_id)
        
        # 3. ê³„ì • ë¹„í™œì„±í™”
        user['is_active'] = False
        user['deleted_at'] = datetime.now()
        
        await db.save_user(user)
        print(f"âœ… {user_id} ë°ì´í„° ìµëª…í™” ì™„ë£Œ (GDPR)")
    
    async def export_user_data(self, user_id: str) -> dict:
        """
        ì‚¬ìš©ì ìš”ì²­ ì‹œ ëª¨ë“  ë°ì´í„° ë‚´ë³´ë‚´ê¸° (Data Portability)
        """
        
        user = await db.get_user(user_id)
        user_videos = await db.get_user_videos(user_id)
        user_interactions = await db.get_user_interactions(user_id)
        
        export_data = {
            'user': user,
            'videos': user_videos,
            'interactions': user_interactions,
            'exported_at': datetime.now().isoformat(),
            'format': 'JSON'
        }
        
        # ZIP íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ ì œê³µ
        return export_data
    
    async def verify_consent(self, user_id: str) -> dict:
        """
        ê°œì¸ì •ë³´ ì²˜ë¦¬ ë™ì˜ ì¶”ì 
        """
        
        return {
            'user_id': user_id,
            'data_collection_consent': True,  # ë°ì´í„° ìˆ˜ì§‘ ë™ì˜
            'marketing_consent': False,  # ë§ˆì¼€íŒ… ë™ì˜
            'third_party_consent': False,  # ì œ3ì ì œê³µ ë™ì˜
            'consented_at': datetime.now(),
            'version': '1.0'  # ì•½ê´€ ë²„ì „ ì¶”ì 
        }
```

#### S3 ì ‘ê·¼ ì œì–´

```python
import boto3
from botocore.config import Config

class S3SecurityConfig:
    """
    AWS S3 ë³´ì•ˆ ì„¤ì •
    """
    
    def __init__(self):
        self.s3_client = boto3.client(
            's3',
            region_name='ap-northeast-2',
            config=Config(
                signature_version='s3v4',
                retries={'max_attempts': 3, 'mode': 'standard'}
            )
        )
        self.bucket_name = 'k-meme-factory-prod'
    
    async def upload_with_signature(self, file_path: str, user_id: str) -> dict:
        """
        ì„œëª…ëœ URLë¡œ ì•ˆì „í•œ ì—…ë¡œë“œ (í´ë¼ì´ì–¸íŠ¸ â†’ S3 ì§ì ‘)
        """
        
        # 1. ì‚¬ìš©ìë³„ í´ë” (user_id/...) ë¡œ ê²©ë¦¬
        s3_key = f"user_content/{user_id}/{uuid.uuid4()}/{file_path.name}"
        
        # 2. ì„œëª…ëœ URL ìƒì„± (1ì‹œê°„ ìœ íš¨)
        presigned_url = self.s3_client.generate_presigned_url(
            'put_object',
            Params={
                'Bucket': self.bucket_name,
                'Key': s3_key,
                'ContentType': file_path.content_type,
                'Metadata': {'user_id': user_id}
            },
            ExpiresIn=3600  # 1ì‹œê°„
        )
        
        return {
            'upload_url': presigned_url,
            's3_key': s3_key,
            'expires_in': 3600
        }
    
    async def set_bucket_policy(self):
        """
        S3 ë²„í‚· ì •ì±… ì„¤ì • (ê³µê°œ ì ‘ê·¼ ì°¨ë‹¨)
        """
        
        bucket_policy = {
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Sid": "DenyInsecureTransport",
                    "Effect": "Deny",
                    "Principal": "*",
                    "Action": "s3:*",
                    "Resource": f"arn:aws:s3:::{self.bucket_name}/*",
                    "Condition": {
                        "Bool": {"aws:SecureTransport": "false"}
                    }
                },
                {
                    "Sid": "AllowCloudFrontAccess",
                    "Effect": "Allow",
                    "Principal": {
                        "AWS": "arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity"
                    },
                    "Action": "s3:GetObject",
                    "Resource": f"arn:aws:s3:::{self.bucket_name}/*"
                }
            ]
        }
        
        self.s3_client.put_bucket_policy(
            Bucket=self.bucket_name,
            Policy=json.dumps(bucket_policy)
        )
        
        print("âœ… S3 ë²„í‚· ì •ì±… ì„¤ì • ì™„ë£Œ (HTTPSë§Œ í—ˆìš©, CloudFront ì ‘ê·¼ë§Œ í—ˆìš©)")
```

---

### 4. ì—ëŸ¬ í•¸ë“¤ë§ & ì¬ì‹œë„ ë¡œì§ (Critical)

```python
import asyncio
from typing import Callable, Any
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

class ResilientAPIClient:
    """
    ì™¸ë¶€ API í˜¸ì¶œ ì‹œ ì¬ì‹œë„ ë° Fallback ì „ëµ
    """
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10),
        retry=retry_if_exception_type((RateLimitError, TimeoutError))
    )
    async def call_gemini_with_retry(
        self,
        video_url: str,
        max_retries: int = 3,
        backoff_factor: float = 2
    ) -> dict:
        """
        Gemini API í˜¸ì¶œ + ìë™ ì¬ì‹œë„
        
        ì¬ì‹œë„ ì „ëµ:
        1ì°¨ ì‹œë„ ì‹¤íŒ¨ â†’ 2ì´ˆ ëŒ€ê¸° â†’ ì¬ì‹œë„
        2ì°¨ ì‹œë„ ì‹¤íŒ¨ â†’ 4ì´ˆ ëŒ€ê¸° â†’ ì¬ì‹œë„
        3ì°¨ ì‹œë„ ì‹¤íŒ¨ â†’ Fallback ì‘ë‹µ ë°˜í™˜
        """
        
        for attempt in range(max_retries):
            try:
                analysis = await gemini.analyze_video(video_url)
                return analysis
            
            except RateLimitError as e:
                if attempt < max_retries - 1:
                    wait_time = backoff_factor ** attempt
                    print(f"â³ Rate Limited. Retry {attempt+1}/{max_retries} after {wait_time}s")
                    await asyncio.sleep(wait_time)
                else:
                    return await self._fallback_gemini_response(video_url, e)
            
            except TimeoutError as e:
                if attempt < max_retries - 1:
                    wait_time = backoff_factor ** attempt
                    print(f"â³ Timeout. Retry {attempt+1}/{max_retries} after {wait_time}s")
                    await asyncio.sleep(wait_time)
                else:
                    return await self._fallback_gemini_response(video_url, e)
            
            except Exception as e:
                print(f"âŒ Unexpected error: {e}")
                return await self._fallback_gemini_response(video_url, e)
        
        return {}
    
    async def _fallback_gemini_response(self, video_url: str, error: Exception) -> dict:
        """
        Gemini API ì‹¤íŒ¨ ì‹œ Fallback (ìºì‹œëœ ë°ì´í„° ë˜ëŠ” ê¸°ë³¸ê°’)
        """
        
        # 1. ìºì‹œì—ì„œ ìœ ì‚¬ ì˜ìƒì˜ ë¶„ì„ ê²°ê³¼ ê²€ìƒ‰
        cached = await redis.get(f"gemini:fallback:{video_url}")
        if cached:
            print(f"ğŸ“¦ Fallback: Using cached analysis for similar video")
            return json.loads(cached)
        
        # 2. ê¸°ë³¸ ë¶„ì„ ì‘ë‹µ ë°˜í™˜ (ìˆ˜ë™ìœ¼ë¡œ ê°œì„  ì˜ˆì •)
        print(f"âš ï¸ Fallback: Returning generic analysis template")
        return {
            "status": "fallback",
            "reason": str(error),
            "metadata": {
                "duration_seconds": 15,  # ê¸°ë³¸ê°’
                "platform": "unknown",
                "bpm": None  # ìˆ˜ë™ ì…ë ¥ í•„ìš”
            },
            "message": "âš ï¸ Gemini ë¶„ì„ ì‹¤íŒ¨. ê´€ë¦¬ìê°€ ìˆ˜ë™ìœ¼ë¡œ ë¶„ì„ ì˜ˆì •."
        }
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    async def call_claude_with_retry(self, prompt: str) -> str:
        """
        Claude API í˜¸ì¶œ + ì¬ì‹œë„
        """
        
        try:
            response = await claude.generate_text(prompt)
            return response
        
        except RateLimitError:
            await asyncio.sleep(5)  # Claude ì¬ì‹œë„
            raise
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    async def call_google_maps_with_retry(self, lat: float, lng: float) -> dict:
        """
        Google Maps API í˜¸ì¶œ + ì¬ì‹œë„
        """
        
        try:
            location_data = await google_maps.reverse_geocode(lat, lng)
            return location_data
        
        except Exception as e:
            print(f"âŒ Maps API Error: {e}")
            # Fallback: ê¸°ì¡´ ìœ„ì¹˜ ë°ì´í„° ë°˜í™˜
            return {
                "lat": lat,
                "lng": lng,
                "place_name": "Unknown Location",
                "cached": True
            }


# ì‚¬ìš© ì˜ˆì‹œ
@app.post("/api/remix/analyze")
async def analyze_video(video_url: str, current_user: dict = Depends(get_current_user)):
    client = ResilientAPIClient()
    
    try:
        # ì¬ì‹œë„ ë¡œì§ í¬í•¨
        analysis = await client.call_gemini_with_retry(video_url)
        
        if analysis.get('status') == 'fallback':
            # Fallback ìƒí™©ì´ë©´ ìˆ˜ë™ ê°œì… í•„ìš” í‘œì‹œ
            await db.create_pending_manual_review(video_url, analysis)
            return {
                "status": "pending_review",
                "message": "ë¶„ì„ ì‹¤íŒ¨. ê´€ë¦¬ìê°€ ê²€í†  ì˜ˆì •ì…ë‹ˆë‹¤."
            }
        
        return analysis
    
    except Exception as e:
        # ìµœì¢… ì‹¤íŒ¨ (ëª¨ë“  ì¬ì‹œë„ ì†Œì§„)
        print(f"ğŸ”´ Critical failure: {e}")
        await sentry.capture_exception(e)
        
        raise HTTPException(
            status_code=503,
            detail="Service temporarily unavailable. Please try again later."
        )
```

---

### 5. ìºì‹± ì „ëµ (Important)

```python
class CachingStrategy:
    """
    Redisë¥¼ í™œìš©í•œ ì²´ê³„ì ì¸ ìºì‹± ì „ëµ
    """
    
    async def cache_gemini_analysis(self, video_url: str, analysis: dict, ttl: int = 86400):
        """
        Gemini ë¶„ì„ ê²°ê³¼ ìºì‹± (24ì‹œê°„)
        
        ì´ìœ : ê°™ì€ ì˜ìƒ ì¬ë¶„ì„ ë°©ì§€ â†’ API ë¹„ìš© ì ˆê°
        """
        cache_key = f"gemini:{video_url}"
        await redis.setex(cache_key, ttl, json.dumps(analysis))
    
    async def cache_rendered_recipe_view(self, node_id: str, html: str, ttl: int = 3600):
        """
        Smart Recipe View ë Œë”ë§ ê²°ê³¼ ìºì‹± (1ì‹œê°„)
        
        ì´ìœ : ì¸ê¸° ë…¸ë“œ ë¹ˆë²ˆí•œ ì¡°íšŒ â†’ HTML ìƒì„± ë°˜ë³µ ë°©ì§€
        """
        cache_key = f"recipe:{node_id}"
        await redis.setex(cache_key, ttl, html)
    
    async def cache_similar_nodes_search(self, query: str, results: list, ttl: int = 3600):
        """
        ìœ ì‚¬ ë…¸ë“œ ê²€ìƒ‰ ê²°ê³¼ ìºì‹± (1ì‹œê°„)
        """
        cache_key = f"similar:{query}"
        await redis.setex(cache_key, ttl, json.dumps(results))
    
    async def invalidate_cache(self, node_id: str):
        """
        ë…¸ë“œ ì—…ë°ì´íŠ¸ ì‹œ ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”
        """
        
        # 1. ë…¸ë“œ ìì²´ ìºì‹œ
        await redis.delete(f"recipe:{node_id}")
        
        # 2. ë¶€ëª¨/ìì‹ ë…¸ë“œ ìºì‹œ
        parent = await db.get_parent_node(node_id)
        if parent:
            await redis.delete(f"recipe:{parent['node_id']}")
        
        # 3. ìœ ì‚¬ ë…¸ë“œ ìºì‹œ (ê´‘ë²”ìœ„ ë¬´íš¨í™”)
        await redis.delete_pattern(f"similar:*")


# Cache-Aside Pattern êµ¬í˜„
@app.get("/api/remix/{node_id}")
async def get_remix_node(node_id: str):
    # 1. ìºì‹œì—ì„œ ì¡°íšŒ
    cache_key = f"recipe:{node_id}"
    cached = await redis.get(cache_key)
    if cached:
        return json.loads(cached)
    
    # 2. DBì—ì„œ ì¡°íšŒ
    node = await db.get_remix_node(node_id)
    
    # 3. ë Œë”ë§
    html = render_smart_recipe_view(node)
    
    # 4. ìºì‹œ ì €ì¥
    await redis.setex(cache_key, 3600, html)
    
    return html
```

---

### 6. í…ŒìŠ¤íŠ¸ ì „ëµ (Important)

```python
# Unit Test ì˜ˆì‹œ (pytest)

import pytest
from unittest.mock import Mock, patch

class TestGeminiAnalysis:
    
    @pytest.mark.asyncio
    async def test_gemini_analysis_success(self):
        """Gemini ë¶„ì„ ì„±ê³µ ì¼€ì´ìŠ¤"""
        
        video_url = "https://tiktok.com/video/123"
        expected_analysis = {
            "duration_seconds": 15,
            "bpm": 128,
            "platform": "tiktok"
        }
        
        # Mock Gemini API
        with patch('gemini.analyze_video') as mock_analyze:
            mock_analyze.return_value = expected_analysis
            
            client = ResilientAPIClient()
            result = await client.call_gemini_with_retry(video_url)
            
            assert result == expected_analysis
            mock_analyze.assert_called_once()
    
    @pytest.mark.asyncio
    async def test_gemini_rate_limit_retry(self):
        """Rate Limit ì‹œ ì¬ì‹œë„"""
        
        # Mock: ì²« í˜¸ì¶œì€ ì‹¤íŒ¨, ë‘ ë²ˆì§¸ëŠ” ì„±ê³µ
        with patch('gemini.analyze_video') as mock_analyze:
            mock_analyze.side_effect = [
                RateLimitError("Too many requests"),
                {"duration_seconds": 15, "bpm": 128}
            ]
            
            client = ResilientAPIClient()
            result = await client.call_gemini_with_retry("url")
            
            assert result["duration_seconds"] == 15
            assert mock_analyze.call_count == 2
    
    @pytest.mark.asyncio
    async def test_gemini_fallback_response(self):
        """ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ ì‹œ Fallback"""
        
        with patch('gemini.analyze_video') as mock_analyze:
            mock_analyze.side_effect = RateLimitError("Persistent failure")
            
            client = ResilientAPIClient()
            result = await client.call_gemini_with_retry("url", max_retries=3)
            
            assert result["status"] == "fallback"
            assert mock_analyze.call_count == 3

# Integration Test ì˜ˆì‹œ
class TestRemixNodeCreation:
    
    @pytest.mark.asyncio
    async def test_full_remix_creation_workflow(self, test_db, test_redis):
        """ì „ì²´ ë¦¬ë¯¹ìŠ¤ ìƒì„± ì›Œí¬í”Œë¡œìš°"""
        
        # 1. Gemini ë¶„ì„
        video_url = "https://tiktok.com/video/test123"
        analysis = await ResilientAPIClient().call_gemini_with_retry(video_url)
        
        # 2. Claude ê¸°íš
        brief = await Claude45Generator().generate_brief(analysis)
        
        # 3. Admin Panel ì—…ë¡œë“œ (ì‹œë®¬ë ˆì´ì…˜)
        node = await create_remix_node(analysis, brief)
        
        # 4. DB í™•ì¸
        saved_node = await test_db.get_remix_node(node.id)
        assert saved_node is not None
        assert saved_node.layer == "master"
        
        # 5. ìºì‹œ í™•ì¸ (ì•ˆ ë¨)
        cached = await test_redis.get(f"recipe:{node.id}")
        assert cached is None  # ì²« ì ‘ê·¼ì´ë¯€ë¡œ ì•„ì§ ìºì‹œ ì—†ìŒ
        
        # 6. ì²« ì ‘ê·¼ ì‹œ ìºì‹œ ìƒì„±
        view = await get_remix_node(node.id)
        cached = await test_redis.get(f"recipe:{node.id}")
        assert cached is not None

# E2E Test ì˜ˆì‹œ (Selenium / Playwright)
class TestUserJourney:
    
    async def test_user_creates_and_shares_remix(self):
        """ì‚¬ìš©ìê°€ ë¦¬ë¯¹ìŠ¤ ìƒì„± â†’ ê³µìœ  â†’ ì„±ê³µ ì¸ì¦"""
        
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()
            
            # 1. ë¡œê·¸ì¸
            await page.goto("https://k-meme.com/login")
            await page.fill("input[name='email']", "test@example.com")
            await page.fill("input[name='password']", "test123")
            await page.click("button:text('ë¡œê·¸ì¸')")
            
            # 2. ë¦¬ë¯¹ìŠ¤ ì„ íƒ
            await page.goto("https://k-meme.com/remix/remix_001")
            
            # 3. ê¸°íš í™•ì¸
            title = await page.text_content("h1")
            assert "ë¦¬ë¯¹ìŠ¤ ì œëª©" in title
            
            # 4. ê°€ì´ë“œ ë‹¤ìš´ë¡œë“œ
            await page.click("a:text('Text Guide')")
            
            # 5. ì´¬ì˜ ì‹œë®¬ë ˆì´ì…˜
            await page.click("button:text('ì´¬ì˜ ì‹œì‘')")
            
            await browser.close()

# í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ëª©í‘œ
# Phase 1 (MVP): 70% ì´ìƒ
# Phase 2: 85% ì´ìƒ
```

---

### 7. ëª¨ë‹ˆí„°ë§ & ì•Œë¦¼ (Important)

```python
import sentry_sdk
from datadog import initialize, api
from opentelemetry import trace, metrics

class ProductionMonitoring:
    """
    Sentry + Datadog + OpenTelemetry í†µí•©
    """
    
    def __init__(self):
        # Sentry ì´ˆê¸°í™” (ì—ëŸ¬ ì¶”ì )
        sentry_sdk.init(
            dsn="https://xxx@sentry.io/xxxx",
            traces_sample_rate=0.1,  # 10% ìƒ˜í”Œë§
            environment="production",
            release="v5.2"
        )
        
        # Datadog ì´ˆê¸°í™” (ì¸í”„ë¼ ëª¨ë‹ˆí„°ë§)
        initialize(
            api_key="xxx",
            app_key="xxx"
        )
        
        # OpenTelemetry ì´ˆê¸°í™” (ë¶„ì‚° ì¶”ì )
        self.tracer = trace.get_tracer(__name__)
    
    async def track_api_latency(self, endpoint: str, duration_ms: float):
        """
        API ë ˆì´í„´ì‹œ ì¶”ì 
        ëª©í‘œ: P95 < 500ms
        """
        
        # Datadogì— ë©”íŠ¸ë¦­ ì „ì†¡
        api.Metric.send(
            metric=f"k_meme.api.latency",
            points=duration_ms,
            tags=[f"endpoint:{endpoint}", "env:prod"]
        )
        
        # Alert: P95 > 500ms
        if duration_ms > 500:
            await self._alert_slack(f"ğŸš¨ API Latency High: {endpoint} took {duration_ms}ms")
    
    async def track_gemini_api_errors(self, error_type: str, error_message: str):
        """
        Gemini API ì—ëŸ¬ìœ¨ ì¶”ì 
        ëª©í‘œ: < 1% ì—ëŸ¬ìœ¨
        """
        
        api.Metric.send(
            metric=f"k_meme.gemini.errors",
            points=1,
            tags=[f"error_type:{error_type}", "env:prod"]
        )
        
        # Sentry ê¸°ë¡
        sentry_sdk.capture_message(f"Gemini Error: {error_message}")
        
        # Alert: ì—ëŸ¬ìœ¨ > 5%
        error_rate = await self._calculate_error_rate("gemini")
        if error_rate > 0.05:
            await self._alert_slack(f"ğŸš¨ Gemini Error Rate: {error_rate*100:.1f}%")
    
    async def track_node_creation_success_rate(self):
        """
        ë…¸ë“œ ìƒì„± ì„±ê³µë¥  ì¶”ì 
        ëª©í‘œ: > 95%
        """
        
        total = await db.count_remix_nodes()
        failed = await db.count_failed_node_creations()
        success_rate = (total - failed) / total
        
        api.Metric.send(
            metric="k_meme.node_creation.success_rate",
            points=success_rate * 100,
            tags=["env:prod"]
        )
        
        if success_rate < 0.95:
            await self._alert_slack(f"âš ï¸ Node Creation Success Rate: {success_rate*100:.1f}%")
    
    async def track_k_success_conversion(self):
        """
        K-Success ì¸ì¦ ì „í™˜ìœ¨ ì¶”ì 
        ëª©í‘œ: > 10%
        """
        
        total_created = await db.count_user_videos()
        k_success_count = await db.count_k_success_videos()
        conversion_rate = k_success_count / total_created if total_created > 0 else 0
        
        api.Metric.send(
            metric="k_meme.k_success.conversion_rate",
            points=conversion_rate * 100,
            tags=["env:prod"]
        )
        
        print(f"ğŸ“Š K-Success Conversion: {conversion_rate*100:.1f}% ({k_success_count}/{total_created})")
    
    async def _calculate_error_rate(self, service: str) -> float:
        """
        ì„œë¹„ìŠ¤ë³„ ì—ëŸ¬ìœ¨ ê³„ì‚°
        """
        total = await redis.get(f"metrics:{service}:total")
        errors = await redis.get(f"metrics:{service}:errors")
        
        if not total or int(total) == 0:
            return 0
        
        return int(errors or 0) / int(total)
    
    async def _alert_slack(self, message: str):
        """
        Slack ì•Œë¦¼ ì „ì†¡
        """
        webhook_url = os.getenv("SLACK_WEBHOOK_URL")
        await aiohttp.post(webhook_url, json={"text": message})


# ë¯¸ë“¤ì›¨ì–´: ëª¨ë“  ìš”ì²­ ì¶”ì 
@app.middleware("http")
async def track_requests(request: Request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    duration_ms = (time.time() - start_time) * 1000
    
    # ë ˆì´í„´ì‹œ ì¶”ì 
    monitoring = ProductionMonitoring()
    await monitoring.track_api_latency(request.url.path, duration_ms)
    
    return response
```

---

## 6. ê¸°ìˆ  ìŠ¤íƒ (Production-Ready, 2025 Current)

```
AI Models (â­ ì¤‘ìš”: í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë²„ì „)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Google Gemini 2.0 Flash Pro (í˜„ì¬ ìµœì‹ )
   - ë¹„ìš©: $0.075/1M input tokens (Flux Pro ëŒ€ë¹„ ì €ë ´)
   - ì†ë„: FlashëŠ” 50% ë” ë¹ ë¦„
   - ì„±ëŠ¥: ì¶©ë¶„í•¨ (ì´ì „ Pro ëŒ€ë¹„)
   - ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½ë¡œ: Gemini 3.0 ì¶œì‹œ ì‹œ êµì²´ ê°€ëŠ¥

âœ… Anthropic Claude 3.5 Sonnet (í˜„ì¬ ìµœì‹ )
   - ë¹„ìš©: $3/1M input tokens
   - ì„±ëŠ¥: Claude 3 Opus ì´ìƒ
   - ì†ë„: ë” ë¹ ë¦„
   - ë§ˆì´ê·¸ë ˆì´ì…˜ ê²½ë¡œ: Claude 4.5 ì¶œì‹œ ì‹œ êµì²´ ê°€ëŠ¥

Backend (Phase 1: 3ê°œ DB, Phase 2: 5ê°œ DB)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Phase 1 (MVP):
  âœ… Python 3.13 LTS
  âœ… FastAPI 0.109+
  âœ… PostgreSQL 16 LTS + pgvector
  âœ… PostGIS 3.4
  âœ… Redis 7.2
  
Phase 2+ (Scale):
  â• Neo4j 5.13 (Viral Genealogy Graph)

Frontend
â”€â”€â”€â”€â”€â”€â”€â”€
âœ… React 18.3 LTS
âœ… Next.js 15 (App Router)
âœ… TypeScript 5.3
âœ… TailwindCSS 3.4
âœ… SWR / Zustand (ìƒíƒœ ê´€ë¦¬)
âœ… Mapbox GL JS

Infrastructure
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Docker 25.0
âœ… GitHub Actions (CI/CD)
âœ… AWS / GCP (App Hosting)
âœ… CloudFlare (WAF, CDN)

Security & Observability
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âœ… Firebase Auth (ë˜ëŠ” Auth0)
âœ… JWT + OAuth2.0
âœ… Sentry (ì—ëŸ¬ ì¶”ì )
âœ… Datadog (ëª¨ë‹ˆí„°ë§)
âœ… OpenTelemetry (ë¶„ì‚° ì¶”ì )
```

---

## 7. ê°œë°œ ìš°ì„ ìˆœìœ„ (ì‹œë‹ˆì–´ ê°œë°œì ê¶Œì¥)

### ğŸ”´ Critical (MVP ì§ì „ í•„ìˆ˜)
```
- [x] AI ëª¨ë¸ ë²„ì „ ìˆ˜ì • (Gemini 2.0, Claude 3.5)
- [ ] ë³´ì•ˆ ì•„í‚¤í…ì²˜ (Auth, Rate Limiting, Data Protection)
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ & ì¬ì‹œë„ ë¡œì§
- [ ] ìºì‹± ì „ëµ ì •ì˜
```

### ğŸŸ¡ Important (Phase 1 ë‚´ ì™„ë£Œ)
```
- [ ] DB ë‹¨ìˆœí™” (Phase 1: 3ê°œ, Phase 2: 5ê°œ)
- [ ] í…ŒìŠ¤íŠ¸ ì „ëµ (70%+ ì»¤ë²„ë¦¬ì§€)
- [ ] ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­ ì •ì˜
```

### ğŸŸ¢ Nice-to-Have (Phase 2)
```
- [ ] ë²¡í„° DB ê³ ë„í™” (pgvector â†’ Supabase)
- [ ] ë¶„ì‚° ì¶”ì  (OpenTelemetry)
```

---

## ìµœì¢… í‰ê°€

### Before (ì‹œë‹ˆì–´ ê°œë°œì ë¦¬ë·° ì „)
```
âœ… ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§: íƒì›”
âŒ ë³´ì•ˆ: ê±°ì˜ ì—†ìŒ
âŒ ì—ëŸ¬ í•¸ë“¤ë§: ì—†ìŒ
âš ï¸ ê¸°ìˆ  ìŠ¤íƒ: ë¯¸ë˜ ëª¨ë¸ ì˜ì¡´
âš ï¸ DB ë³µì¡ë„: ê³¼ë„í•¨
```

### After (ì´ ë¬¸ì„œ ì ìš© í›„)
```
âœ… ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§: íƒì›”
âœ… ë³´ì•ˆ: Production-grade
âœ… ì—ëŸ¬ í•¸ë“¤ë§: ì™„ë²½
âœ… ê¸°ìˆ  ìŠ¤íƒ: í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ë²„ì „
âœ… DB ë³µì¡ë„: ë‹¨ê³„ì  ë„ì…
```

---

**ì¤€ë¹„ë¨. ì´ì œ ì •ë§ ê°œë°œì„ ì‹œì‘í•˜ì„¸ìš”!** ğŸš€

**Document Version**: 5.2 Final (Senior Developer Review Applied)
**Status**: âœ… Production-Ready
**Target**: CTO, ê°œë°œíŒ€ (ì¦‰ì‹œ ì°©ìˆ˜)