"""
Gemini Pipeline - VDG (Video Data Graph) v3.0 (PEGL v1.0)
Uses Gemini 3.0 Pro to extract the 'Brain' of the viral video.

PEGL v1.0: ìŠ¤í‚¤ë§ˆ ê²€ì¦ ì ìš©
- ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ë²„ì „ ê²€ì¦
- í•„ìˆ˜ í•„ë“œ ê²€ì¦
"""
import os
import json
import logging
from typing import Optional, Dict, Any, List
from google import genai
from google.genai import types
from app.config import settings
from app.schemas.vdg import VDG
from app.services.video_downloader import video_downloader
from app.validators.schema_validator import validate_vdg_analysis_schema, SchemaValidationError

logger = logging.getLogger(__name__)

VDG_PROMPT = """
ë‹¹ì‹ ì€ ë°”ì´ëŸ´ ì˜ìƒ ì „ë¬¸ê°€ AI (Gemini 3.0 Pro)ìž…ë‹ˆë‹¤.
ì´ ë°”ì´ëŸ´ ì˜ìƒì„ **VDG (Video Data Graph) v3.3** í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.

## ì¤‘ìš”: í•œê¸€ë¡œ ë¶„ì„
- ëª¨ë“  í…ìŠ¤íŠ¸ ì¶œë ¥ì€ **í•œê¸€**ë¡œ ìž‘ì„±
- summary, dialogue, location, hook_script ë“± ëª¨ë‘ í•œê¸€
- ì˜ì–´ ë²ˆì—­ í•„ë“œëŠ” ìƒëžµ

## ANALYSIS GOALS

### 1. HOOK ANALYSIS (0-5ì´ˆ)
- **Microbeats**: í›…ì„ startâ†’buildâ†’punch ë¹„íŠ¸ë¡œ ë¶„í•´
- **Virality Analysis**: ì™œ ìŠ¤í¬ë¡¤ì„ ë©ˆì¶”ê²Œ í•˜ëŠ”ê°€?
  - curiosity_gap: ì–´ë–¤ ê¶ê¸ˆì¦ì„ ìœ ë°œí•˜ëŠ”ê°€?
  - meme_potential: remixable_action | catchphrase | reaction_face | dance | low
  - engagement_pattern: watch_in_loop | share_trigger | comment_bait | scroll_stop

### 2. NARRATIVE STRUCTURE (scenes)
ê° ì”¬ì—ì„œ ì‹ë³„:
- **Dialogue**: ì „ì²´ ëŒ€ì‚¬ (ì›ë³¸ ì–¸ì–´ ê·¸ëŒ€ë¡œ, ì™¸êµ­ì–´ë©´ í•œê¸€ ë²ˆì—­ í¬í•¨)
- **Rhetoric**: sarcasm, rhetorical_question, ad_hominem, hyperbole, irony
- **Comedic Device**: expectation_subversion, anticlimax, juxtaposition, callback, slapstick
- **Shots**: ì¹´ë©”ë¼ ì›Œí¬ (ìƒ· íƒ€ìž…, ì•µê¸€, ë¬´ë¸Œë¨¼íŠ¸)

### 3. FOCUS WINDOWS (RLìš©)
ì‹œì²­ìž ì£¼ì˜ ì§‘ì¤‘ êµ¬ê°„ 3-5ê°œ:
- **Hotspot scores**: hook (0-1), interest (0-1), boundary (0-1)
- **Mise-en-scÃ¨ne**: composition, lighting, lens, camera_move
- **Entities**: ìºë¦­í„°/ì˜¤ë¸Œì íŠ¸ (pose, emotion, outfit)
- **Tags**: narrative_roles (SETUP, TURN, REVEAL, PUNCHLINE)

### 4. CROSS-SCENE ANALYSIS (íŒ¨í„´ í•©ì„±)
- **Consistent elements**: ì”¬ ê°„ ì¼ê´€ëœ ìš”ì†Œ
- **Evolving elements**: ë³€í™”í•˜ëŠ” ìš”ì†Œ
- **Director intent**: ì—°ì¶œ ì˜ë„

### 5. SENTIMENT ARC
ê°ì • ë³€í™” ì¶”ì :
- start_sentiment, end_sentiment, trajectory

### 6. ASR/OCR EXTRACTION
- **asr_transcript**: ìŒì„± ì „ì‚¬ (í•œê¸€ë¡œ)
- **ocr_text**: í™”ë©´ í…ìŠ¤íŠ¸ (í•œê¸€ë¡œ)

### 7. PSYCHOLOGICAL AUDIT
- **Irony Analysis**: ê¸°ëŒ€ vs í˜„ì‹¤ ê°­
- **Dopamine Radar**: 0-10 ì ìˆ˜

### 8. PRODUCT PLACEMENT (O2O)
ì œí’ˆ/ë¸Œëžœë“œ ë“±ìž¥ ì‹œ:
- product_mentions: ì´ë¦„, ë¸Œëžœë“œ, ì¹´í…Œê³ ë¦¬
- cta_types: link_bio, swipe_up, discount_code

### 9. AUDIENCE REACTION
- viral_signal: ë°”ì´ëŸ´ í•µì‹¬ ì´ìœ  (í•œê¸€)
- overall_sentiment: positive/negative/mixed

### 10. REPLICATION GUIDE (capsule_brief)
- hook_script: í›… ìž¬í˜„ ë°©ë²• (í•œê¸€)
- shotlist: [{seq, duration, action, shot}]
- do_not: í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒë“¤ (í•œê¸€)

### 11. REMIX SUGGESTIONS (ë³€ì£¼ ì œì•ˆ) - í•„ìˆ˜ 2ê°œ ì´ìƒ
ê° ë³€ì£¼ ì œì•ˆì—ëŠ”:
- target_niche: ì–´ë–¤ í¬ë¦¬ì—ì´í„°ê°€ í™œìš©í•  ìˆ˜ ìžˆëŠ”ê°€ (ì˜ˆ: "ë·°í‹° ë¦¬ë·°ì–´", "ë¨¹ë°© í¬ë¦¬ì—ì´í„°")
- concept: ë³€ì£¼ ì»¨ì…‰ (ì˜ˆ: "ì´ í¬ë§·ì— í™”ìž¥í’ˆ ë¦¬ë·°ë¥¼ ìž…ížˆë©´...")
- template_type: re_enact | mashup | parody | product_placement
- viral_element_to_keep: ë°˜ë“œì‹œ ìœ ì§€í•´ì•¼ í•  ë°”ì´ëŸ´ ìš”ì†Œ
- variable_elements: ë³€ê²½ ê°€ëŠ¥í•œ ìš”ì†Œë“¤

### 12. PRODUCT PLACEMENT GUIDE (ì²´í—˜ë‹¨ ë³€ì£¼ìš©)
ì œí’ˆ/ë¸Œëžœë“œë¥¼ ìžì—°ìŠ¤ëŸ½ê²Œ ì‚½ìž…í•˜ë ¤ë©´:
- recommended_timing: ì œí’ˆ ë“±ìž¥ ì¶”ì²œ ì‹œì  (ì˜ˆ: "ì¤‘ë°˜ 3-5ì´ˆ")
- invariant_elements: ë°˜ë“œì‹œ ìœ ì§€í•  ìš”ì†Œ (Hook êµ¬ì¡° ë“±)
- variable_elements: ë³€ì£¼ ê°€ëŠ¥í•œ ìš”ì†Œ (ì†Œìž¬, ì¸ë¬¼ ë“±)
- product_slot: ì œí’ˆ ì‚½ìž… ìœ„ì¹˜ (ì˜ˆ: "ì†Œí’ˆ ìžë¦¬ì— ì œí’ˆ ëŒ€ì²´")

## OUTPUT SCHEMA (JSON Only)
{
  "content_id": "video_id",
  "platform": "youtube|tiktok|instagram",
  "title": "ì¶”ë¡ ëœ ì œëª© (í•œê¸€)",
  "duration_sec": 8.0,
  "upload_date": null,
  "summary": "2ë¬¸ìž¥ í•œê¸€ ìš”ì•½",
  
  "metrics": {
    "view_count": 0, "like_count": 0, "comment_count": 0,
    "hashtags": ["#funny", "#viral"]
  },
  
  "hook_genome": {
    "start_sec": 0.0, "end_sec": 3.0,
    "pattern": "subversion|problem_solution|question|pattern_break",
    "delivery": "dialogue|visual_gag|voiceover",
    "strength": 0.85,
    "hook_summary": "í•œ ë¬¸ìž¥ ì„¤ëª… (í•œê¸€)",
    "microbeats": [
      {"t": 0.5, "role": "start", "cue": "audio", "note": "ì†ë‹˜ì´ ì •ì¤‘í•˜ê²Œ ì§ˆë¬¸"},
      {"t": 2.1, "role": "build", "cue": "audio", "note": "ì‚¬ìž¥ì´ ë¹„ê¼¬ëŠ” ë‹µë³€"},
      {"t": 4.2, "role": "punch", "cue": "audio", "note": "ì§ì ‘ì ì¸ ìš•ì„¤ íˆ¬ì²™"}
    ],
    "virality_analysis": {
      "curiosity_gap": "ì†ë‹˜ì´ ì–´ë–»ê²Œ ë°˜ì‘í• ê¹Œ?",
      "meme_potential": "remixable_action",
      "relatability_factor": "surprise_reveal",
      "engagement_pattern": "watch_in_loop"
    },
    "information_density": "low"
  },
  
  "scenes": [{
    "scene_id": "S01",
    "time_start": 0.0, "time_end": 8.0, "duration_sec": 8.0,
    "narrative_unit": {
      "role": "Hook",
      "summary": "í•œê¸€ ìš”ì•½",
      "dialogue": "ëŒ€ì‚¬ ì›ë³¸ (ì™¸êµ­ì–´ë©´ í•œê¸€ ë²ˆì—­)",
      "dialogue_lang": "ko",
      "rhetoric": ["sarcasm", "rhetorical_question"],
      "comedic_device": ["expectation_subversion", "anticlimax"]
    },
    "setting": {
      "location": "ì‹ë‹¹",
      "visual_style": {"lighting": "Natural", "edit_pace": "slow"},
      "audio_style": {"audio_events": []}
    },
    "shots": [{"shot_id": "S01_01", "start": 0.0, "end": 8.0, "camera": {"shot": "MS", "angle": "eye", "move": "static"}}]
  }],
  
  "focus_windows": [
    {
      "window_id": "W00",
      "t_window": [0, 3.5],
      "hotspot": {
        "reasons": ["hook", "cv_change"],
        "scores": {"hook": 0.9, "interest": 0.8, "boundary": 0.6},
        "confidence": 0.9
      },
      "mise_en_scene": {
        "composition": {"grid": "center", "subject_size": "CU"},
        "lighting": {"type": "soft_light"},
        "lens": {"fov_class": "medium", "dof": "shallow"},
        "camera_move": "static"
      },
      "entities": [
        {"label": "ì£¼ì¸ê³µ", "traits": {"pose": "ì•‰ì•„ìžˆìŒ", "emotion": "ë¬´í‘œì •"}, "role_in_window": "SUBJECT"}
      ],
      "parent_scene_id": "S01",
      "tags": {"narrative_roles": ["SETUP"], "cinematic": ["STATIC_SHOT", "CLOSE_UP"]}
    }
  ],
  
  "cross_scene_analysis": {
    "global_summary": "ì…‹ì—…ë¶€í„° íŽ€ì¹˜ë¼ì¸ê¹Œì§€ ì™„ê²°ëœ ì„œì‚¬ êµ¬ì¡° (í•œê¸€)",
    "consistent_elements": [
      {"aspect": "composition", "evidence": "ì¤‘ì•™ í”„ë ˆì´ë° ìœ ì§€", "scenes": ["S01"]}
    ],
    "evolving_elements": [
      {"dimension": "emotion_arc", "description": "ë¬´í‘œì • â†’ ê¸´ìž¥ â†’ ì›ƒìŒ", "evidence": "í‘œì • ë³€í™”", "pattern": "escalating"}
    ],
    "director_intent": [
      {"technique": "slow_long_take", "intended_effect": "comedic_timing", "rationale": "ëŒ€ì‚¬ì— ì§‘ì¤‘", "evidence": {"scenes": ["S01"], "cues": ["no cuts"]}}
    ],
    "entity_state_changes": [
      {"entity_id": "ì†ë‹˜", "initial_state": "ì •ì¤‘í•œ ì†ë‹˜", "final_state": "ë‹¹ë‹¹í•œ ì†Œë¹„ìž", "triggering_event": "ì‚¬ìž¥ì˜ ìš•ì„¤", "scene_id": "S01", "time_span": [4.2, 7.8]}
    ]
  },
  
  "asr_transcript": {
    "lang": "ko",
    "transcript": "ìŒì„± ì „ì‚¬ (í•œê¸€)"
  },
  
  "ocr_text": [
    {"text": "ìžë§‰ í…ìŠ¤íŠ¸", "lang": "ko", "timestamp": 2.5}
  ],
  
  "intent_layer": {
    "hook_trigger": "shock",
    "hook_trigger_reason": "í•œê¸€ ì„¤ëª…",
    "retention_strategy": "í•œê¸€ ì„¤ëª…",
    "irony_analysis": {"setup": "í•œê¸€", "twist": "í•œê¸€", "gap_type": "expectation_subversion"},
    "dopamine_radar": {"visual_spectacle": 3, "audio_stimulation": 5, "narrative_intrigue": 8, "emotional_resonance": 6, "comedy_shock": 10},
    "sentiment_arc": {
      "start_sentiment": "neutral",
      "end_sentiment": "amused",
      "micro_shifts": [
        {"t": 2.1, "from_emotion": "neutral", "to_emotion": "tense", "cue": "ë¹„ê¼¬ëŠ” ë‹µë³€"}
      ],
      "trajectory": "ê¸´ìž¥ê° ìƒìŠ¹ í›„ ìœ ë¨¸ë¡œ ì „í™˜"
    }
  },
  
  "commerce": {
    "product_mentions": [],
    "service_mentions": [],
    "cta_types": [],
    "has_sponsored_content": false
  },
  
  "remix_suggestions": [
    {
      "target_niche": "ë·°í‹° ë¦¬ë·°ì–´",
      "concept": "ì´ ë¦¬ì•¡ì…˜ í¬ë§·ì— í™”ìž¥í’ˆ ì‚¬ìš© ì „í›„ ë¹„êµë¥¼ ìž…ížˆë©´ ìžì—°ìŠ¤ëŸ½ê²Œ ë°”ì´ëŸ´ ê°€ëŠ¥",
      "template_type": "product_placement",
      "viral_element_to_keep": "ë¬´í‘œì • â†’ ë†€ëžŒ â†’ ë§Œì¡± ê°ì • ë³€í™” êµ¬ì¡°",
      "variable_elements": ["ì†Œìž¬ë¥¼ ë·°í‹° ì œí’ˆìœ¼ë¡œ êµì²´", "ë°°ê²½ì„ í™”ìž¥ëŒ€ë¡œ ë³€ê²½"]
    },
    {
      "target_niche": "ë¨¹ë°© í¬ë¦¬ì—ì´í„°",
      "concept": "ìŒì‹ ë¦¬ë·°ì— ì´ ì„œí”„ë¼ì´ì¦ˆ í¬ë§· ì ìš©",
      "template_type": "re_enact",
      "viral_element_to_keep": "3ì´ˆ ë‚´ í˜¸ê¸°ì‹¬ ìœ ë°œ Hook",
      "variable_elements": ["ì¸ë¬¼ êµì²´", "ìŒì‹ìœ¼ë¡œ ì†Œìž¬ ë³€ê²½"]
    }
  ],
  
  "capsule_brief": {
    "hook_script": "í›… ìž¬í˜„ ë°©ë²• (í•œê¸€)",
    "shotlist": [{"seq": 1, "duration": 3.0, "action": "í•œê¸€ ì•¡ì…˜", "shot": "MS"}],
    "constraints": {"min_actors": 2, "locations": ["ì‹ë‹¹"], "props": [], "difficulty": "ì‰¬ì›€", "primary_challenge": "ì½”ë¯¹ íƒ€ì´ë°"},
    "do_not": ["ìºë¦­í„° ê¹¨ì§€ ë§ ê²ƒ"],
    "product_placement_guide": {
      "recommended_timing": "ì¤‘ë°˜ 3-5ì´ˆ ì‚¬ì´ ìžì—°ìŠ¤ëŸ½ê²Œ",
      "invariant_elements": ["Hook êµ¬ì¡° (ì²˜ìŒ 3ì´ˆ)", "ê°ì • ë³€í™” íŒ¨í„´"],
      "variable_elements": ["ì†Œìž¬/ì œí’ˆ", "ì´¬ì˜ ìž¥ì†Œ", "ì¸ë¬¼"],
      "product_slot": "ì†Œí’ˆ ìžë¦¬ì— ì œí’ˆ ëŒ€ì²´"
    }
  },
  
  "audience_reaction": {
    "analysis": "ì‹œì²­ìžê°€ ì™œ ì´ë ‡ê²Œ ë°˜ì‘í–ˆëŠ”ì§€ ë¶„ì„ (í•œê¸€)",
    "common_reactions": ["ì›ƒìŒ", "ë¹ˆì •ê±°ë¦¼ ê³µê°", "ê³µê°"],
    "overall_sentiment": "positive",
    "viral_signal": "ë°”ì´ëŸ´ í•µì‹¬ ì´ìœ  í•œ ì¤„ (í•œê¸€)"
  }
}
"""


class GeminiPipeline:
    def __init__(self):
        self.model = settings.GEMINI_MODEL
        # Prefer GEMINI_API_KEY first (GOOGLE_API_KEY was leaked)
        api_key = settings.GEMINI_API_KEY or settings.GOOGLE_API_KEY
        if api_key:
            if settings.GEMINI_API_KEY and settings.GOOGLE_API_KEY:
                logger.info("Using GEMINI_API_KEY (preferred)")
            self.client = genai.Client(api_key=api_key)
        else:
            self.client = None
            logger.warning("No API key set. GeminiPipeline will use mock data.")

    async def analyze_video(
        self, 
        video_url: str, 
        node_id: str,
        audience_comments: Optional[List[Dict[str, Any]]] = None
    ) -> VDG:
        """
        Full pipeline: Download -> Upload -> Analyze (VDG) -> Parse -> Return
        
        Args:
            video_url: Video URL to analyze
            node_id: Node ID for tracking
            audience_comments: Optional list of best comments for context
                [{"text": "...", "likes": 123, "lang": "en"}, ...]
        """
        if not self.client:
            logger.info("No API key, returning mock VDG data.")
            return self._get_mock_data(node_id)

        temp_path = None
        try:
            # 1. Download Video
            logger.warning(f"ðŸ“¥ Downloading video from {video_url}...")
            temp_path, metadata = await video_downloader.download(video_url)
            try:
                size_mb = os.path.getsize(temp_path) / (1024 * 1024)
                logger.warning(f"ðŸ“¦ Downloaded size: {size_mb:.2f} MB ({temp_path})")
            except Exception as e:
                logger.warning(f"ðŸ“¦ Downloaded size unavailable: {e}")
            
            # 2. Build inline video part (base64)
            try:
                with open(temp_path, "rb") as video_fp:
                    video_bytes = video_fp.read()
            except Exception as e:
                raise Exception(f"Failed to read downloaded video: {e}") from e

            if not video_bytes:
                raise Exception("Downloaded video is empty")

            size_mb = len(video_bytes) / (1024 * 1024)
            if size_mb > 20:
                logger.warning(
                    f"âš ï¸ Inline video size is {size_mb:.2f} MB (>20MB). "
                    "Gemini API may reject inline uploads."
                )
            logger.warning(f"ðŸ“¦ Inline video bytes: {len(video_bytes)}")

            video_part = types.Part(
                inline_data=types.Blob(
                    data=video_bytes,
                    mime_type="video/mp4"
                )
            )

            # 3. Build prompt with audience comments context
            enhanced_prompt = VDG_PROMPT
            if audience_comments:
                comments_text = "\n".join([
                    f"- [{c.get('likes', 0)} likes] {c.get('text', '')[:200]}"
                    for c in audience_comments[:10]
                ])
                enhanced_prompt = f"""
## AUDIENCE REACTIONS (Best Comments by Likes)
The following are the top comments from real viewers. Use these to understand WHY this video went viral:

{comments_text}

Consider these reactions when analyzing the hook effectiveness, emotional impact, and virality factors.

---

{VDG_PROMPT}
"""
                logger.info(f"ðŸ“ Including {len(audience_comments)} audience comments in analysis")

            # 4. Generate Analysis
            logger.warning(f"ðŸ§  Analyzing {node_id} with {self.model} (VDG v3.0)...")

            def _build_config(use_schema: bool) -> types.GenerateContentConfig:
                if use_schema:
                    return types.GenerateContentConfig(
                        response_mime_type="application/json",
                        response_json_schema=VDG.model_json_schema()
                    )
                return types.GenerateContentConfig(response_mime_type="application/json")

            def _looks_like_schema_error(message: str) -> bool:
                msg = message.lower()
                return "schema" in msg or "response_json_schema" in msg

            def _generate(model_name: str, use_schema: bool):
                logger.warning(f"ðŸ“¦ Generate with model={model_name} inline=True schema={use_schema}")
                return self.client.models.generate_content(
                    model=model_name,
                    contents=[video_part, enhanced_prompt],
                    config=_build_config(use_schema)
                )

            use_schema = True
            last_err: Optional[Exception] = None
            response = None

            models_to_try = [self.model]
            if not self.model.startswith("models/"):
                models_to_try.append(f"models/{self.model}")

            for model_name in models_to_try:
                try:
                    response = _generate(model_name, use_schema)
                    break
                except Exception as e:
                    if use_schema and _looks_like_schema_error(str(e)):
                        logger.warning("âš ï¸ Response schema rejected, retrying without schema")
                        use_schema = False
                        try:
                            response = _generate(model_name, use_schema)
                            break
                        except Exception as retry_err:
                            last_err = retry_err
                            logger.warning(f"âŒ Model retry failed: {retry_err}")
                            continue
                    last_err = e
                    logger.warning(f"âŒ Model failed: {model_name} error={e}")
                    continue

            if response is None and last_err is not None:
                raise last_err


            # 4. Parse Response
            try:
                result_json = json.loads(response.text)
                result_json = self._sanitize_vdg_payload(result_json)
                result_json["content_id"] = node_id
                
                # PEGL v1.0: ìŠ¤í‚¤ë§ˆ ë²„ì „ ì¶”ê°€ (ì—†ìœ¼ë©´)
                if "schema_version" not in result_json:
                    result_json["schema_version"] = "v3.2"
                
                # PEGL v1.0: ìŠ¤í‚¤ë§ˆ ê²€ì¦ (ì‹¤íŒ¨ ì‹œ ëª…ì‹œì  ì˜ˆì™¸)
                try:
                    validate_vdg_analysis_schema(result_json)
                except SchemaValidationError as e:
                    logger.error(f"Schema validation failed: {e}")
                    # ê²€ì¦ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰í•˜ë˜ ê²½ê³  ë¡œê·¸
                    # í”„ë¡œë•ì…˜ì—ì„œëŠ” raiseë¡œ ë³€ê²½ ê°€ëŠ¥
                    logger.warning(f"Continuing despite schema validation failure for {node_id}")
                
                # Create VDG object
                vdg = VDG(**result_json)
                
                # === ADAPTER: Populate Legacy Fields ===
                self._populate_legacy_fields(vdg)
                
                # === VDG Quality Validation ===
                try:
                    from app.validators.vdg_quality_validator import validate_vdg_quality
                    quality_result = validate_vdg_quality(result_json)
                    
                    if quality_result.is_valid:
                        logger.info(f"âœ… VDG quality check PASSED (score: {quality_result.score})")
                    else:
                        logger.warning(
                            f"âš ï¸ VDG quality check FAILED (score: {quality_result.score})\n"
                            f"   Issues: {quality_result.issues[:3]}"
                        )
                    
                    # í’ˆì§ˆ ë©”íƒ€ë°ì´í„° ì²¨ë¶€ (result_jsonì— ì¶”ê°€)
                    result_json["_quality_score"] = quality_result.score
                    result_json["_quality_valid"] = quality_result.is_valid
                    result_json["_quality_issues"] = quality_result.issues[:5]
                    
                except Exception as e:
                    logger.warning(f"VDG quality validation skipped: {e}")
                
                logger.info(f"âœ… VDG analysis complete for {node_id}")
                return vdg

            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse Gemini JSON response: {e}")
                logger.error(f"Raw response: {response.text[:500]}...")
                raise SchemaValidationError(f"Invalid JSON from Gemini: {e}", context="gemini_response")
            except Exception as e:
                logger.error(f"Failed to parse Gemini response: {e}")
                logger.error(f"Raw response: {response.text[:500]}...")
                raise e

        except Exception as e:
            logger.error(f"âŒ Gemini analysis failed: {e}")
            raise e
        finally:
            if temp_path and os.path.exists(temp_path):
                os.remove(temp_path)

    def _sanitize_vdg_payload(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Coerce known schema edge-cases from LLM output before Pydantic validation."""
        scenes = payload.get("scenes", [])
        for scene in scenes:
            setting = scene.get("setting") or {}
            audio_style = setting.get("audio_style") or {}
            audio_events = audio_style.get("audio_events")
            if isinstance(audio_events, list):
                normalized = []
                for idx, event in enumerate(audio_events):
                    if isinstance(event, dict):
                        normalized.append(event)
                    elif isinstance(event, str):
                        normalized.append(
                            {
                                "timestamp": 0.0,
                                "event": "note",
                                "description": event,
                                "intensity": "medium",
                            }
                        )
                audio_style["audio_events"] = normalized
                setting["audio_style"] = audio_style
                scene["setting"] = setting

        commerce = payload.get("commerce") or {}
        service_mentions = commerce.get("service_mentions")
        if isinstance(service_mentions, list):
            normalized_services = []
            for item in service_mentions:
                if isinstance(item, str):
                    normalized_services.append(item)
                elif isinstance(item, dict):
                    name = item.get("name") or item.get("brand") or item.get("category")
                    normalized_services.append(name or str(item))
                else:
                    normalized_services.append(str(item))
            commerce["service_mentions"] = normalized_services
            payload["commerce"] = commerce

        # === Localization Check: Detect English-only fields ===
        # If scene summary is English-only, add summary_ko = None for frontend fallback
        for scene in scenes:
            nu = scene.get("narrative_unit", {})
            summary = nu.get("summary", "")
            if summary:
                # Check if summary contains Korean characters
                has_korean = any('\uac00' <= c <= '\ud7a3' for c in summary)
                if not has_korean:
                    # English-only summary detected - mark for frontend
                    nu["summary_ko"] = None
                    logger.warning(
                        f"Scene {scene.get('scene_id', '?')} has English-only summary: "
                        f"{summary[:50]}... (will show [EN] in UI)"
                    )
                else:
                    # Korean summary - copy to summary_ko for explicit handling
                    nu["summary_ko"] = summary
                scene["narrative_unit"] = nu

        return payload

    def _populate_legacy_fields(self, vdg: VDG) -> None:
        """Populate legacy compatibility fields for frontend"""
        # global_context
        hook = vdg.hook_genome
        intent = vdg.intent_layer
        
        vdg.global_context = {
            "title": vdg.title[:100] if vdg.title else "Analyzed Video",
            "mood": "dynamic", # simplified
            "keywords": ["viral", vdg.platform, intent.hook_trigger],
            "hashtags": [],
            "video_id": vdg.content_id,
            "hook_pattern": hook.pattern,
            "hook_delivery": hook.delivery,
            "hook_strength_score": hook.strength,
            "viral_hook_summary": hook.hook_summary,
            "key_action_description": intent.hook_trigger_reason
        }
        
        # scene_frames (simplified from scenes)
        frames = []
        for scene in vdg.scenes:
            for shot in scene.shots:
                frame = {
                    "timestamp": shot.start,
                    "duration": shot.end - shot.start,
                    "description": shot.keyframes[0].desc if shot.keyframes else scene.narrative_unit.summary,
                    "camera": {
                        "type": shot.camera.move,
                        "shot_size": shot.camera.shot,
                        "angle": shot.camera.angle
                    }
                }
                frames.append(frame)
        vdg.scene_frames = frames

    def _get_mock_data(self, video_id: str) -> VDG:
        """Return mock VDG data when API key is not available"""
        # (Mock implementation simplified for brevity)
        return VDG(
            content_id=video_id,
            title="Mock Video",
            duration_sec=15.0,
            summary="Mock summary",
            hook_genome=dict(hook_summary="Mock hook", strength=0.8),
            scenes=[],
            intent_layer=dict(
                hook_trigger="shock", 
                irony_analysis=dict(setup="A", twist="B"),
                dopamine_radar=dict(visual_spectacle=5, audio_stimulation=5, narrative_intrigue=5, emotional_resonance=5, comedy_shock=5)
            ),
            remix_suggestions=[],
            capsule_brief=dict(hook_script="Mock script", constraints=dict(primary_challenge="Mock challenge"))
        )

gemini_pipeline = GeminiPipeline()
