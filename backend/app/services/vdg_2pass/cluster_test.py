"""
Cluster Test Service (P1-3)

Proof-ready ë…¸ë“œë§Œì„ ëŒ€ìƒìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í…ŒìŠ¤íŠ¸ ìˆ˜í–‰

1. proof_ready=trueì¸ kicksë§Œ ëŒ€ìƒ
2. mechanism ê¸°ë°˜ signature ìƒì„±
3. í´ëŸ¬ìŠ¤í„° í• ë‹¹ ë° ì„±ê³¼ ì¶”ì 

ì‚¬ìš©:
    from app.services.vdg_2pass.cluster_test import cluster_test_service
    clusters = await cluster_test_service.run_test(db)
"""
import hashlib
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field
from collections import defaultdict
from datetime import datetime, timezone

from sqlalchemy import select, func
from sqlalchemy.ext.asyncio import AsyncSession

logger = logging.getLogger(__name__)


@dataclass
class ClusterCandidate:
    """í´ëŸ¬ìŠ¤í„° í›„ë³´ ë…¸ë“œ"""
    node_id: str
    kick_ids: List[str]
    mechanisms: List[str]
    avg_confidence: float
    evidence_score: float
    signature: str


@dataclass
class ClusterResult:
    """í´ëŸ¬ìŠ¤í„° ê²°ê³¼"""
    cluster_id: str
    signature: str
    member_count: int
    members: List[ClusterCandidate]
    dominant_mechanisms: List[str]
    avg_confidence: float
    quality_score: float


class ClusterTestService:
    """
    Proof-Ready ë…¸ë“œ í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸ ì„œë¹„ìŠ¤
    
    1. DBì—ì„œ proof_ready kicks ì¡°íšŒ
    2. mechanism ê¸°ë°˜ signature ìƒì„±
    3. signature ìœ ì‚¬ë„ë¡œ í´ëŸ¬ìŠ¤í„°ë§
    4. í´ëŸ¬ìŠ¤í„° í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    """
    
    MIN_CONFIDENCE = 0.6  # í´ëŸ¬ìŠ¤í„°ë§ ëŒ€ìƒ ìµœì†Œ ì‹ ë¢°ë„
    MIN_CLUSTER_SIZE = 2  # ìµœì†Œ í´ëŸ¬ìŠ¤í„° í¬ê¸°
    MECHANISM_WEIGHTS = {
        # ë©”ì»¤ë‹ˆì¦˜ ìœ í˜•ë³„ ê°€ì¤‘ì¹˜
        "hook": 2.0,
        "ë°˜ì „": 1.5,
        "ê°ì •": 1.3,
        "ë¯¸ì¥ì„¼": 1.2,
        "default": 1.0,
    }
    
    async def run_test(
        self,
        db: AsyncSession,
        min_confidence: float = 0.6,
        limit: int = 500,
    ) -> Dict[str, Any]:
        """
        í´ëŸ¬ìŠ¤í„° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        
        Args:
            db: Database session
            min_confidence: ìµœì†Œ ì‹ ë¢°ë„ í•„í„°
            limit: ìµœëŒ€ ì²˜ë¦¬ ë…¸ë“œ ìˆ˜
            
        Returns:
            {
                "total_candidates": int,
                "total_clusters": int,
                "clusters": List[ClusterResult],
                "unclustered": int,
                "quality_summary": dict,
            }
        """
        from app.models import ViralKick, RemixNode
        
        logger.info(f"ğŸ§ª Starting cluster test with min_confidence={min_confidence}")
        
        # 1. proof_ready kicks ì¡°íšŒ
        query = (
            select(ViralKick)
            .where(ViralKick.proof_ready == True)
            .where(ViralKick.confidence >= min_confidence)
            .order_by(ViralKick.confidence.desc())
            .limit(limit)
        )
        
        result = await db.execute(query)
        kicks = result.scalars().all()
        
        if not kicks:
            logger.warning("No proof-ready kicks found")
            return {
                "total_candidates": 0,
                "total_clusters": 0,
                "clusters": [],
                "unclustered": 0,
                "quality_summary": {},
            }
        
        logger.info(f"ğŸ“Š Found {len(kicks)} proof-ready kicks")
        
        # 2. ë…¸ë“œë³„ kicks ê·¸ë£¹í™”
        node_kicks = defaultdict(list)
        for kick in kicks:
            node_kicks[str(kick.node_id)].append(kick)
        
        # 3. í´ëŸ¬ìŠ¤í„° í›„ë³´ ìƒì„±
        candidates = []
        for node_id, node_kick_list in node_kicks.items():
            candidate = self._create_candidate(node_id, node_kick_list)
            if candidate:
                candidates.append(candidate)
        
        logger.info(f"ğŸ¯ Created {len(candidates)} cluster candidates")
        
        # 4. Signature ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§
        clusters = self._cluster_by_signature(candidates)
        
        # 5. ê²°ê³¼ ì§‘ê³„
        clustered_count = sum(c.member_count for c in clusters)
        unclustered_count = len(candidates) - clustered_count
        
        quality_summary = self._calculate_quality_summary(clusters)
        
        logger.info(f"âœ… Cluster test complete: {len(clusters)} clusters, {unclustered_count} unclustered")
        
        return {
            "total_candidates": len(candidates),
            "total_clusters": len(clusters),
            "clusters": [self._cluster_to_dict(c) for c in clusters],
            "unclustered": unclustered_count,
            "quality_summary": quality_summary,
            "run_at": datetime.now(timezone.utc).isoformat(),
        }
    
    def _create_candidate(
        self, 
        node_id: str, 
        kicks: List[Any]
    ) -> Optional[ClusterCandidate]:
        """í´ëŸ¬ìŠ¤í„° í›„ë³´ ìƒì„±"""
        if not kicks:
            return None
        
        mechanisms = [k.mechanism for k in kicks if k.mechanism]
        if not mechanisms:
            return None
        
        # Signature ìƒì„± (ë©”ì»¤ë‹ˆì¦˜ ì •ê·œí™” í›„ í•´ì‹œ)
        normalized = sorted(set(self._normalize_mechanism(m) for m in mechanisms))
        signature = hashlib.md5("|".join(normalized).encode()).hexdigest()[:12]
        
        # ì ìˆ˜ ê³„ì‚°
        avg_confidence = sum(k.confidence for k in kicks) / len(kicks)
        
        # Evidence score (comment + frame ì¦ê±° ìˆ˜)
        evidence_score = sum(
            len(k.comment_evidence_ids or []) + len(k.frame_evidence_ids or [])
            for k in kicks
        ) / len(kicks)
        
        return ClusterCandidate(
            node_id=node_id,
            kick_ids=[k.kick_id for k in kicks],
            mechanisms=normalized,
            avg_confidence=avg_confidence,
            evidence_score=evidence_score,
            signature=signature,
        )
    
    def _normalize_mechanism(self, mechanism: str) -> str:
        """ë©”ì»¤ë‹ˆì¦˜ ì •ê·œí™” (í‚¤ì›Œë“œ ì¶”ì¶œ)"""
        # í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = []
        
        mechanism_lower = mechanism.lower()
        
        # í•µì‹¬ íŒ¨í„´ ë§¤ì¹­
        patterns = [
            ("hook", ["hook", "í›…", "ì²«"]),
            ("ë°˜ì „", ["ë°˜ì „", "twist", "ì „í™˜"]),
            ("ê°ì •", ["ê°ì •", "emotion", "í‘œì •", "ë¦¬ì•¡ì…˜"]),
            ("ë¯¸ì¥ì„¼", ["ë¯¸ì¥ì„¼", "ì•µê¸€", "êµ¬ë„", "í”„ë ˆì´ë°"]),
            ("ë¦¬ë“¬", ["ë°•ì", "ë¦¬ë“¬", "ë¹„íŠ¸", "íƒ€ì´ë°"]),
            ("ì„œì‚¬", ["ìŠ¤í† ë¦¬", "ì„œì‚¬", "ë‚´ëŸ¬í‹°ë¸Œ"]),
        ]
        
        for keyword, triggers in patterns:
            if any(t in mechanism_lower for t in triggers):
                keywords.append(keyword)
        
        if not keywords:
            # ì²« 20ìë¥¼ í•´ì‹œë¡œ ì‚¬ìš©
            return hashlib.md5(mechanism[:20].encode()).hexdigest()[:8]
        
        return "_".join(sorted(set(keywords)))
    
    def _cluster_by_signature(
        self, 
        candidates: List[ClusterCandidate]
    ) -> List[ClusterResult]:
        """Signature ê¸°ë°˜ í´ëŸ¬ìŠ¤í„°ë§"""
        # Signatureë³„ ê·¸ë£¹í™”
        sig_groups = defaultdict(list)
        for c in candidates:
            sig_groups[c.signature].append(c)
        
        clusters = []
        for signature, members in sig_groups.items():
            if len(members) < self.MIN_CLUSTER_SIZE:
                continue
            
            # ì§€ë°°ì  ë©”ì»¤ë‹ˆì¦˜ ì°¾ê¸°
            mechanism_counts = defaultdict(int)
            for m in members:
                for mech in m.mechanisms:
                    mechanism_counts[mech] += 1
            
            dominant = sorted(mechanism_counts.items(), key=lambda x: -x[1])[:3]
            dominant_mechanisms = [m[0] for m in dominant]
            
            # í´ëŸ¬ìŠ¤í„° í’ˆì§ˆ ì ìˆ˜
            avg_conf = sum(m.avg_confidence for m in members) / len(members)
            avg_evidence = sum(m.evidence_score for m in members) / len(members)
            quality_score = (avg_conf * 0.6 + min(avg_evidence / 5, 1) * 0.4)
            
            clusters.append(ClusterResult(
                cluster_id=f"cl_{signature}",
                signature=signature,
                member_count=len(members),
                members=members,
                dominant_mechanisms=dominant_mechanisms,
                avg_confidence=avg_conf,
                quality_score=quality_score,
            ))
        
        # í’ˆì§ˆìˆœ ì •ë ¬
        clusters.sort(key=lambda c: -c.quality_score)
        
        return clusters
    
    def _calculate_quality_summary(
        self, 
        clusters: List[ClusterResult]
    ) -> Dict[str, Any]:
        """ì „ì²´ í’ˆì§ˆ ìš”ì•½"""
        if not clusters:
            return {
                "avg_cluster_size": 0,
                "avg_quality_score": 0,
                "top_mechanisms": [],
            }
        
        total_members = sum(c.member_count for c in clusters)
        avg_size = total_members / len(clusters)
        avg_quality = sum(c.quality_score for c in clusters) / len(clusters)
        
        # Top mechanisms across all clusters
        mech_counts = defaultdict(int)
        for c in clusters:
            for m in c.dominant_mechanisms:
                mech_counts[m] += c.member_count
        
        top_mechanisms = sorted(mech_counts.items(), key=lambda x: -x[1])[:5]
        
        return {
            "avg_cluster_size": round(avg_size, 1),
            "avg_quality_score": round(avg_quality, 3),
            "top_mechanisms": [{"mechanism": m, "count": c} for m, c in top_mechanisms],
        }
    
    def _cluster_to_dict(self, cluster: ClusterResult) -> Dict[str, Any]:
        """ClusterResultë¥¼ dictë¡œ ë³€í™˜"""
        return {
            "cluster_id": cluster.cluster_id,
            "signature": cluster.signature,
            "member_count": cluster.member_count,
            "dominant_mechanisms": cluster.dominant_mechanisms,
            "avg_confidence": round(cluster.avg_confidence, 3),
            "quality_score": round(cluster.quality_score, 3),
            "members": [
                {
                    "node_id": m.node_id,
                    "kick_ids": m.kick_ids,
                    "mechanisms": m.mechanisms,
                    "avg_confidence": round(m.avg_confidence, 3),
                    "evidence_score": round(m.evidence_score, 2),
                }
                for m in cluster.members
            ],
        }


# Singleton
cluster_test_service = ClusterTestService()
