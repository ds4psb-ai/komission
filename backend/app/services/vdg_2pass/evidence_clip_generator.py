"""
Evidence-Guided Clip Generator (P0-5)

ëŒ“ê¸€/CV ì‹ í˜¸ ê¸°ë°˜ìœ¼ë¡œ ê³ ë°€ë„ ë¶„ì„ì´ í•„ìš”í•œ êµ¬ê°„ì„ ì‹ë³„

2-Pass "ë”¥ë‹¤ì´ë¸Œ"ì˜ í•µì‹¬ì„ 1íšŒ í˜¸ì¶œë¡œ ë³µì›:
- ëŒ“ê¸€ì—ì„œ timestamp íŒíŠ¸ ì¶”ì¶œ ("0:05", "1ë¶„ 20ì´ˆ")
- Scene boundary ê°ì§€ (ffmpeg scene detect)
- ê¸°ë³¸ í›… ìœˆë„ìš° (0-5s)

ì‚¬ìš©:
    from app.services.vdg_2pass.evidence_clip_generator import evidence_clip_generator
    clips = evidence_clip_generator.generate_clips(video_path, comments, duration_sec)
"""
import re
import logging
import subprocess
import json
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass, field

logger = logging.getLogger(__name__)


@dataclass
class EvidenceClip:
    """Evidence ê¸°ë°˜ í´ë¦½ ì •ë³´"""
    clip_id: str
    start_ms: int
    end_ms: int
    fps: float = 10.0  # High density
    reason: str = ""
    source: str = ""  # "hook_window" | "comment_hint" | "scene_cut"
    priority: int = 1  # 1=highest


class EvidenceGuidedClipGenerator:
    """ëŒ“ê¸€/CV ì‹ í˜¸ ê¸°ë°˜ ê³ ë°€ë„ í´ë¦½ ìƒì„±ê¸°"""
    
    DEFAULT_HOOK_WINDOW_MS = 5000  # 0-5ì´ˆ
    DEFAULT_CLIP_DURATION_MS = 4000  # Â±2ì´ˆ = 4ì´ˆ
    DEFAULT_HIGH_DENSITY_FPS = 10.0
    MAX_CLIPS = 6
    
    # í•œêµ­ì–´ timestamp íŒ¨í„´
    TIMESTAMP_PATTERNS = [
        # MM:SS format
        (r'(\d{1,2}):(\d{2})', lambda m: (int(m.group(1)) * 60 + int(m.group(2))) * 1000),
        # "Nì´ˆ" format
        (r'(\d+)ì´ˆ', lambda m: int(m.group(1)) * 1000),
        # "Në¶„ Mì´ˆ" format
        (r'(\d+)ë¶„\s*(\d+)?ì´ˆ?', lambda m: (int(m.group(1)) * 60 + int(m.group(2) or 0)) * 1000),
        # "0:05" style quotes
        (r'"(\d{1,2}):(\d{2})"', lambda m: (int(m.group(1)) * 60 + int(m.group(2))) * 1000),
    ]
    
    def generate_clips(
        self,
        video_path: str,
        comments: List[Dict[str, Any]],
        duration_sec: float,
        include_scene_cuts: bool = True
    ) -> List[EvidenceClip]:
        """
        ê³ ë°€ë„ ë¶„ì„ì´ í•„ìš”í•œ í´ë¦½ ëª©ë¡ ìƒì„±
        
        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            comments: ëŒ“ê¸€ ë¦¬ìŠ¤íŠ¸ [{"text": str, "likes": int}, ...]
            duration_sec: ë¹„ë””ì˜¤ ê¸¸ì´ (ì´ˆ)
            include_scene_cuts: Scene cut ê°ì§€ í¬í•¨ ì—¬ë¶€
            
        Returns:
            List[EvidenceClip] (priority ìˆœ ì •ë ¬)
        """
        duration_ms = int(duration_sec * 1000)
        clips: List[EvidenceClip] = []
        used_windows: List[Tuple[int, int]] = []
        
        # 1. ê¸°ë³¸ í›… ìœˆë„ìš° (í•­ìƒ í¬í•¨, priority 1)
        hook_end = min(self.DEFAULT_HOOK_WINDOW_MS, duration_ms)
        clips.append(EvidenceClip(
            clip_id="clip.hook_0_5",
            start_ms=0,
            end_ms=hook_end,
            fps=self.DEFAULT_HIGH_DENSITY_FPS,
            reason="default_hook_window",
            source="hook_window",
            priority=1
        ))
        used_windows.append((0, hook_end))
        
        # 2. ëŒ“ê¸€ì—ì„œ timestamp íŒíŠ¸ ì¶”ì¶œ
        timestamp_hints = self._extract_timestamp_hints(comments)
        for i, hint in enumerate(timestamp_hints[:3]):  # ìµœëŒ€ 3ê°œ
            t_ms = hint['t_ms']
            
            # ë²”ìœ„ ì²´í¬
            if t_ms < 0 or t_ms > duration_ms:
                continue
            
            # ì¤‘ë³µ ì²´í¬
            if self._overlaps_existing(t_ms, used_windows, margin_ms=2000):
                continue
            
            start_ms = max(0, t_ms - 2000)
            end_ms = min(duration_ms, t_ms + 2000)
            
            clips.append(EvidenceClip(
                clip_id=f"clip.comment_{t_ms}",
                start_ms=start_ms,
                end_ms=end_ms,
                fps=self.DEFAULT_HIGH_DENSITY_FPS,
                reason=f"comment_timestamp_hint: {hint['source']}",
                source="comment_hint",
                priority=2
            ))
            used_windows.append((start_ms, end_ms))
        
        # 3. Scene cuts (ffmpeg ê¸°ë°˜)
        if include_scene_cuts and len(clips) < self.MAX_CLIPS:
            scene_cuts = self._detect_scene_cuts(video_path, duration_ms)
            for cut_ms in scene_cuts[:2]:  # ìµœëŒ€ 2ê°œ
                if self._overlaps_existing(cut_ms, used_windows, margin_ms=2000):
                    continue
                
                start_ms = max(0, cut_ms - 1500)
                end_ms = min(duration_ms, cut_ms + 1500)
                
                clips.append(EvidenceClip(
                    clip_id=f"clip.scene_{cut_ms}",
                    start_ms=start_ms,
                    end_ms=end_ms,
                    fps=self.DEFAULT_HIGH_DENSITY_FPS,
                    reason=f"scene_cut_at_{cut_ms}ms",
                    source="scene_cut",
                    priority=3
                ))
                used_windows.append((start_ms, end_ms))
        
        # Priority ì •ë ¬
        clips.sort(key=lambda c: c.priority)
        
        logger.info(f"ğŸ“¹ Generated {len(clips)} evidence clips: {[c.clip_id for c in clips]}")
        
        return clips[:self.MAX_CLIPS]
    
    def _extract_timestamp_hints(
        self, 
        comments: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        ëŒ“ê¸€ì—ì„œ timestamp íŒíŠ¸ ì¶”ì¶œ
        
        ì˜ˆ: "0:05 ë¶€ë¶„ ë¯¸ì³¤ë‹¤" â†’ {"t_ms": 5000, "source": "MM:SS"}
        """
        hints = []
        seen_timestamps = set()
        
        for c in comments:
            text = c.get('text', '') or ''
            
            for pattern, converter in self.TIMESTAMP_PATTERNS:
                match = re.search(pattern, text)
                if match:
                    try:
                        t_ms = converter(match)
                        
                        # Dedup (Â±1ì´ˆ ë²”ìœ„)
                        rounded = (t_ms // 1000) * 1000
                        if rounded not in seen_timestamps:
                            seen_timestamps.add(rounded)
                            hints.append({
                                't_ms': t_ms,
                                'source': pattern[:10],
                                'comment_text': text[:50],
                                'likes': c.get('likes', 0)
                            })
                            break  # í•˜ë‚˜ë§Œ ì¶”ì¶œ
                    except (ValueError, TypeError):
                        continue
        
        # ì¢‹ì•„ìš” ìˆœ ì •ë ¬
        hints.sort(key=lambda h: h.get('likes', 0), reverse=True)
        
        return hints
    
    def _detect_scene_cuts(
        self, 
        video_path: str, 
        duration_ms: int
    ) -> List[int]:
        """
        ffmpeg scene detectionìœ¼ë¡œ scene cut ìœ„ì¹˜ íƒì§€
        
        Returns:
            List of timestamps in milliseconds
        """
        try:
            cmd = [
                'ffprobe', '-v', 'quiet',
                '-show_entries', 'packet=pts_time,flags',
                '-select_streams', 'v:0',
                '-of', 'json',
                video_path
            ]
            
            # Alternative: use scene detection filter
            scene_cmd = [
                'ffmpeg', '-i', video_path,
                '-vf', 'select=gt(scene\\,0.3),showinfo',
                '-f', 'null', '-'
            ]
            
            # Run with timeout
            result = subprocess.run(
                scene_cmd,
                capture_output=True,
                text=True,
                timeout=180  # 3ë¶„ (ê¸´ ì˜ìƒ ì§€ì›)
            )
            
            # Parse scene changes from stderr
            scene_times = []
            for line in result.stderr.split('\n'):
                if 'pts_time:' in line:
                    match = re.search(r'pts_time:([\d.]+)', line)
                    if match:
                        t_sec = float(match.group(1))
                        t_ms = int(t_sec * 1000)
                        if 1000 < t_ms < duration_ms - 1000:  # Skip very start/end
                            scene_times.append(t_ms)
            
            return sorted(set(scene_times))[:4]  # Max 4 scene cuts
            
        except subprocess.TimeoutExpired:
            logger.warning("Scene detection timed out")
            return []
        except FileNotFoundError:
            logger.warning("ffmpeg not found for scene detection")
            return []
        except Exception as e:
            logger.warning(f"Scene detection failed: {e}")
            return []
    
    def _overlaps_existing(
        self, 
        t_ms: int, 
        used_windows: List[Tuple[int, int]],
        margin_ms: int = 2000
    ) -> bool:
        """ê¸°ì¡´ ìœˆë„ìš°ì™€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸"""
        for start, end in used_windows:
            if start - margin_ms <= t_ms <= end + margin_ms:
                return True
        return False
    
    def format_for_prompt(self, clips: List[EvidenceClip]) -> str:
        """í´ë¦½ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ìš© ë¬¸ìì—´ë¡œ í¬ë§·"""
        lines = ["=== EVIDENCE-GUIDED FOCUS WINDOWS ==="]
        lines.append("ë‹¤ìŒ êµ¬ê°„ì—ì„œ íŠ¹íˆ ì¦ê±°ë¥¼ ì°¾ìœ¼ì„¸ìš”:\n")
        
        for clip in clips:
            start_sec = clip.start_ms / 1000
            end_sec = clip.end_ms / 1000
            lines.append(f"- [{clip.clip_id}] {start_sec:.1f}s - {end_sec:.1f}s ({clip.reason})")
        
        lines.append("\nê° viral_kickì€ ìœ„ focus window ì¤‘ í•˜ë‚˜ë¥¼ ë°˜ë“œì‹œ ì»¤ë²„í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        return "\n".join(lines)


# Singleton instance
evidence_clip_generator = EvidenceGuidedClipGenerator()
